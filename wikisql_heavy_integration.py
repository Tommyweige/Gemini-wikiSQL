#!/usr/bin/env python3
"""
WikiSQL Heavy Integration - æ•´åˆMake It Heavyå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
å°†Make It Heavyçš„å¤šæ™ºèƒ½ä½“åˆ†æèƒ½åŠ›åº”ç”¨äºSQLæŸ¥è¯¢ç”Ÿæˆå’ŒéªŒè¯
"""

import os
import sys
import json
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path

# æ·»åŠ make-it-heavyåˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent / "make-it-heavy"))

try:
    from orchestrator import TaskOrchestrator
    from agent import OpenRouterAgent
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥Make It Heavyæ¨¡å—: {e}")
    print("è¯·ç¡®ä¿make-it-heavyé¡¹ç›®åœ¨æ­£ç¡®ä½ç½®")
    sys.exit(1)

from wikisql_llm_direct import WikiSQLDirectLLM

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WikiSQLHeavyAgent:
    """WikiSQL Heavyæ™ºèƒ½ä½“ - ä¸“é—¨ç”¨äºSQLæŸ¥è¯¢åˆ†æ"""
    
    def __init__(self, agent_id: int, config: dict):
        """
        åˆå§‹åŒ–WikiSQL Heavyæ™ºèƒ½ä½“
        
        Args:
            agent_id: æ™ºèƒ½ä½“ID
            config: é…ç½®ä¿¡æ¯
        """
        self.agent_id = agent_id
        self.config = config
        # ä½¿ç”¨Google AI Studioé…ç½®
        from langchain_google_genai import ChatGoogleGenerativeAI
        self.agent = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0.1,
            google_api_key=os.getenv("GOOGLE_API_KEY"),
            request_timeout=60,
            verbose=False
        )
        
        # å®šä¹‰ä¸“é—¨çš„SQLåˆ†æè§’è‰²
        self.sql_roles = {
            0: "SQLè¯­æ³•ä¸“å®¶ - ä¸“æ³¨äºSQLè¯­æ³•æ­£ç¡®æ€§å’Œä¼˜åŒ–",
            1: "æ•°æ®åˆ†æå¸ˆ - ä¸“æ³¨äºæŸ¥è¯¢é€»è¾‘å’Œæ•°æ®ç†è§£", 
            2: "æ€§èƒ½ä¼˜åŒ–å¸ˆ - ä¸“æ³¨äºæŸ¥è¯¢æ€§èƒ½å’Œæ•ˆç‡",
            3: "ç»“æœéªŒè¯å¸ˆ - ä¸“æ³¨äºç»“æœå‡†ç¡®æ€§å’ŒéªŒè¯"
        }
        
        self.role = self.sql_roles.get(agent_id, "é€šç”¨SQLåˆ†æå¸ˆ")
        
    def analyze_sql_query(self, question: str, table_info: dict, generated_sql: str) -> dict:
        """
        åˆ†æSQLæŸ¥è¯¢
        
        Args:
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            table_info: è¡¨æ ¼ä¿¡æ¯
            generated_sql: ç”Ÿæˆçš„SQLæŸ¥è¯¢
            
        Returns:
            åˆ†æç»“æœ
        """
        # æ„å»ºä¸“é—¨çš„SQLåˆ†ææç¤º
        analysis_prompt = self._build_sql_analysis_prompt(
            question, table_info, generated_sql
        )
        
        try:
            # ä½¿ç”¨æ™ºèƒ½ä½“è¿›è¡Œåˆ†æ - ä½¿ç”¨ChatOpenAIçš„invokeæ–¹æ³•
            response = self.agent.invoke(analysis_prompt)
            analysis_result = response.content
            
            return {
                "agent_id": self.agent_id,
                "role": self.role,
                "analysis": analysis_result,
                "confidence": self._calculate_confidence(analysis_result),
                "recommendations": self._extract_recommendations(analysis_result)
            }
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä½“ {self.agent_id} åˆ†æå¤±è´¥: {e}")
            return {
                "agent_id": self.agent_id,
                "role": self.role,
                "error": str(e),
                "analysis": None
            }
    
    def _build_sql_analysis_prompt(self, question: str, table_info: dict, sql: str) -> str:
        """æ„å»ºSQLåˆ†ææç¤ºè¯"""
        base_prompt = f"""
ä½œä¸º{self.role}ï¼Œè¯·åˆ†æä»¥ä¸‹SQLæŸ¥è¯¢ï¼š

è‡ªç„¶è¯­è¨€é—®é¢˜: {question}

è¡¨æ ¼ä¿¡æ¯:
{json.dumps(table_info, indent=2, ensure_ascii=False)}

ç”Ÿæˆçš„SQLæŸ¥è¯¢:
{sql}

è¯·ä»ä½ çš„ä¸“ä¸šè§’åº¦æä¾›è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬ï¼š
"""
        
        # æ ¹æ®æ™ºèƒ½ä½“è§’è‰²æ·»åŠ ç‰¹å®šåˆ†æè¦æ±‚
        if self.agent_id == 0:  # SQLè¯­æ³•ä¸“å®¶
            specific_prompt = """
1. SQLè¯­æ³•æ­£ç¡®æ€§æ£€æŸ¥
2. è¯­æ³•ä¼˜åŒ–å»ºè®®
3. æ ‡å‡†SQLå…¼å®¹æ€§
4. æ½œåœ¨è¯­æ³•é”™è¯¯è¯†åˆ«
"""
        elif self.agent_id == 1:  # æ•°æ®åˆ†æå¸ˆ
            specific_prompt = """
1. æŸ¥è¯¢é€»è¾‘æ­£ç¡®æ€§
2. æ•°æ®ç†è§£å‡†ç¡®æ€§
3. ä¸šåŠ¡é€»è¾‘åŒ¹é…åº¦
4. æŸ¥è¯¢ç»“æœé¢„æœŸåˆ†æ
"""
        elif self.agent_id == 2:  # æ€§èƒ½ä¼˜åŒ–å¸ˆ
            specific_prompt = """
1. æŸ¥è¯¢æ€§èƒ½è¯„ä¼°
2. ç´¢å¼•ä½¿ç”¨å»ºè®®
3. æŸ¥è¯¢ä¼˜åŒ–æ–¹æ¡ˆ
4. æ‰§è¡Œæ•ˆç‡åˆ†æ
"""
        else:  # ç»“æœéªŒè¯å¸ˆ
            specific_prompt = """
1. ç»“æœå‡†ç¡®æ€§éªŒè¯
2. è¾¹ç•Œæ¡ä»¶æ£€æŸ¥
3. å¼‚å¸¸æƒ…å†µå¤„ç†
4. ç»“æœå¯é æ€§è¯„ä¼°
"""
        
        return base_prompt + specific_prompt + "\nè¯·æä¾›å…·ä½“ã€å¯æ“ä½œçš„åˆ†æå’Œå»ºè®®ã€‚"
    
    def _calculate_confidence(self, analysis: str) -> float:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        if not analysis:
            return 0.0
        
        # ç®€å•çš„ç½®ä¿¡åº¦è®¡ç®—ï¼ˆå¯ä»¥æ”¹è¿›ï¼‰
        confidence_keywords = [
            "æ­£ç¡®", "å‡†ç¡®", "ä¼˜ç§€", "å®Œç¾", "ç¬¦åˆ",
            "å»ºè®®", "æ¨è", "åº”è¯¥", "å¯ä»¥", "éœ€è¦"
        ]
        
        keyword_count = sum(1 for keyword in confidence_keywords if keyword in analysis)
        return min(keyword_count / len(confidence_keywords), 1.0)
    
    def _extract_recommendations(self, analysis: str) -> List[str]:
        """æå–å»ºè®®"""
        if not analysis:
            return []
        
        recommendations = []
        lines = analysis.split('\n')
        
        for line in lines:
            line = line.strip()
            if any(keyword in line for keyword in ["å»ºè®®", "æ¨è", "åº”è¯¥", "éœ€è¦", "å¯ä»¥"]):
                if len(line) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                    recommendations.append(line)
        
        return recommendations[:5]  # æœ€å¤šè¿”å›5ä¸ªå»ºè®®

class WikiSQLHeavyOrchestrator:
    """WikiSQL Heavyç¼–æ’å™¨ - åè°ƒå¤šä¸ªæ™ºèƒ½ä½“è¿›è¡ŒSQLåˆ†æ"""
    
    def __init__(self, config_path: str = "make-it-heavy/config.yaml"):
        """
        åˆå§‹åŒ–Heavyç¼–æ’å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.config = self._load_config()
        self.num_agents = 4  # ä½¿ç”¨4ä¸ªä¸“é—¨çš„SQLåˆ†ææ™ºèƒ½ä½“
        
        # åˆå§‹åŒ–æ™ºèƒ½ä½“
        self.agents = []
        for i in range(self.num_agents):
            agent = WikiSQLHeavyAgent(i, self.config)
            self.agents.append(agent)
        
        logger.info(f"åˆå§‹åŒ–äº† {self.num_agents} ä¸ªWikiSQL Heavyæ™ºèƒ½ä½“")
    
    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            import yaml
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤é…ç½® - ä½¿ç”¨ä¸WikiSQLç›¸åŒçš„ç«¯ç‚¹
            return {
                'openrouter': {
                    'api_key': os.getenv('GOOGLE_API_KEY', ''),
                    'model': 'gemini-2.5-flash',
                    'base_url': 'https://aistudio.google.com/v1'
                }
            }
    
    def heavy_sql_analysis(self, question: str, table_info: dict, generated_sql: str) -> dict:
        """
        æ‰§è¡ŒHeavy SQLåˆ†æ
        
        Args:
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            table_info: è¡¨æ ¼ä¿¡æ¯
            generated_sql: ç”Ÿæˆçš„SQLæŸ¥è¯¢
            
        Returns:
            ç»¼åˆåˆ†æç»“æœ
        """
        logger.info("å¼€å§‹Heavy SQLåˆ†æ...")
        
        # å¹¶è¡Œæ‰§è¡Œå¤šæ™ºèƒ½ä½“åˆ†æ
        agent_results = []
        
        for agent in self.agents:
            logger.info(f"æ™ºèƒ½ä½“ {agent.agent_id} ({agent.role}) å¼€å§‹åˆ†æ...")
            result = agent.analyze_sql_query(question, table_info, generated_sql)
            agent_results.append(result)
        
        # ç»¼åˆåˆ†æç»“æœ
        synthesis = self._synthesize_results(agent_results)
        
        return {
            "question": question,
            "generated_sql": generated_sql,
            "agent_analyses": agent_results,
            "synthesis": synthesis,
            "overall_confidence": synthesis.get("confidence", 0.0),
            "final_recommendations": synthesis.get("recommendations", [])
        }
    
    def _synthesize_results(self, agent_results: List[dict]) -> dict:
        """ç»¼åˆå¤šä¸ªæ™ºèƒ½ä½“çš„åˆ†æç»“æœ"""
        # æ”¶é›†æ‰€æœ‰å»ºè®®
        all_recommendations = []
        total_confidence = 0.0
        valid_analyses = 0
        
        for result in agent_results:
            if result.get("analysis") and not result.get("error"):
                all_recommendations.extend(result.get("recommendations", []))
                total_confidence += result.get("confidence", 0.0)
                valid_analyses += 1
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        avg_confidence = total_confidence / valid_analyses if valid_analyses > 0 else 0.0
        
        # å»é‡å’Œæ’åºå»ºè®®
        unique_recommendations = list(set(all_recommendations))
        
        # ç”Ÿæˆç»¼åˆè¯„ä¼°
        synthesis_summary = self._generate_synthesis_summary(agent_results)
        
        return {
            "confidence": avg_confidence,
            "recommendations": unique_recommendations[:10],  # æœ€å¤š10ä¸ªå»ºè®®
            "summary": synthesis_summary,
            "valid_analyses": valid_analyses,
            "total_agents": len(agent_results)
        }
    
    def _generate_synthesis_summary(self, agent_results: List[dict]) -> str:
        """ç”Ÿæˆç»¼åˆè¯„ä¼°æ‘˜è¦"""
        successful_analyses = [r for r in agent_results if not r.get("error")]
        failed_analyses = [r for r in agent_results if r.get("error")]
        
        summary_parts = []
        
        if successful_analyses:
            summary_parts.append(f"âœ… {len(successful_analyses)} ä¸ªæ™ºèƒ½ä½“æˆåŠŸå®Œæˆåˆ†æ")
            
            # æŒ‰è§’è‰²æ€»ç»“
            for result in successful_analyses:
                role = result.get("role", "æœªçŸ¥è§’è‰²")
                confidence = result.get("confidence", 0.0)
                summary_parts.append(f"  - {role}: ç½®ä¿¡åº¦ {confidence:.2f}")
        
        if failed_analyses:
            summary_parts.append(f"âŒ {len(failed_analyses)} ä¸ªæ™ºèƒ½ä½“åˆ†æå¤±è´¥")
        
        return "\n".join(summary_parts)

class WikiSQLDirectLLMHeavy(WikiSQLDirectLLM):
    """å¢å¼ºç‰ˆWikiSQLç›´æ¥LLMæŸ¥è¯¢åŠ©æ‰‹ - é›†æˆHeavyåˆ†æ"""
    
    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆåŠ©æ‰‹"""
        super().__init__(*args, **kwargs)
        
        # åˆå§‹åŒ–Heavyç¼–æ’å™¨
        try:
            self.heavy_orchestrator = WikiSQLHeavyOrchestrator()
            self.heavy_enabled = True
            logger.info("âœ… Heavyæ¨¡å¼å·²å¯ç”¨")
        except Exception as e:
            logger.warning(f"âš ï¸ Heavyæ¨¡å¼åˆå§‹åŒ–å¤±è´¥: {e}")
            self.heavy_orchestrator = None
            self.heavy_enabled = False
    
    def generate_sql_with_heavy_analysis(self, question: str, table_id: str) -> dict:
        """
        ç”ŸæˆSQLå¹¶è¿›è¡ŒHeavyåˆ†æ
        
        Args:
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            table_id: è¡¨æ ¼ID
            
        Returns:
            åŒ…å«Heavyåˆ†æçš„ç»“æœ
        """
        # 1. ç”ŸæˆåŸºç¡€SQL
        basic_sql = self.generate_sql(question, table_id)
        
        result = {
            "question": question,
            "table_id": table_id,
            "basic_sql": basic_sql,
            "heavy_analysis": None,
            "heavy_enabled": self.heavy_enabled
        }
        
        # 2. å¦‚æœHeavyæ¨¡å¼å¯ç”¨ï¼Œè¿›è¡Œæ·±åº¦åˆ†æ
        if self.heavy_enabled and basic_sql:
            try:
                table_info = self._get_table_info_for_heavy(table_id)
                heavy_analysis = self.heavy_orchestrator.heavy_sql_analysis(
                    question, table_info, basic_sql
                )
                result["heavy_analysis"] = heavy_analysis
                
                logger.info(f"âœ… Heavyåˆ†æå®Œæˆï¼Œç½®ä¿¡åº¦: {heavy_analysis.get('overall_confidence', 0.0):.2f}")
                
            except Exception as e:
                logger.error(f"âŒ Heavyåˆ†æå¤±è´¥: {e}")
                result["heavy_error"] = str(e)
        
        return result
    
    def _get_table_info_for_heavy(self, table_id: str) -> dict:
        """è·å–è¡¨æ ¼ä¿¡æ¯ç”¨äºHeavyåˆ†æ"""
        if table_id not in self.current_tables:
            return {}
        
        table = self.current_tables[table_id]
        
        return {
            "table_id": table_id,
            "headers": table.header,
            "types": table.types,
            "sample_rows": table.rows[:3] if table.rows else [],
            "total_rows": len(table.rows),
            "db_table_name": self.current_table_mapping.get(table_id, "unknown")
        }
    
    def query_with_heavy(self, question: str, table_id: Optional[str] = None) -> dict:
        """
        æ‰§è¡Œå¸¦Heavyåˆ†æçš„æŸ¥è¯¢
        
        Args:
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            table_id: è¡¨æ ¼ID
            
        Returns:
            æŸ¥è¯¢ç»“æœå’ŒHeavyåˆ†æ
        """
        # æ¨æ–­table_idï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not table_id and self.current_questions:
            for q in self.current_questions:
                if question.lower() in q.question.lower():
                    table_id = q.table_id
                    break
            if not table_id:
                table_id = self.current_questions[0].table_id
        
        if not table_id:
            return {"error": "æ— æ³•ç¡®å®šè¡¨æ ¼ID"}
        
        # ç”ŸæˆSQLå’ŒHeavyåˆ†æ
        heavy_result = self.generate_sql_with_heavy_analysis(question, table_id)
        
        # æ‰§è¡ŒSQLè·å–ç»“æœ
        if heavy_result.get("basic_sql"):
            try:
                query_result = self.execute_sql(heavy_result["basic_sql"])
                heavy_result["query_result"] = query_result
            except Exception as e:
                heavy_result["query_error"] = str(e)
        
        return heavy_result

def single_question_test(assistant):
    """å•ä¸ªé—®é¢˜è¯¦ç»†æµ‹è¯•"""
    if not assistant.current_questions:
        print("âŒ æ²¡æœ‰å¯æµ‹è¯•çš„é—®é¢˜")
        return
    
    test_question = assistant.current_questions[0].question
    print(f"\nğŸ“ æµ‹è¯•é—®é¢˜: {test_question}")
    print(f"ğŸ“‹ è¡¨æ ¼ID: {assistant.current_questions[0].table_id}")
    
    # æ‰§è¡ŒHeavyæŸ¥è¯¢
    print("\nğŸ§  æ‰§è¡ŒHeavyåˆ†æ...")
    heavy_result = assistant.query_with_heavy(test_question)
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ” HEAVYåˆ†æè¯¦ç»†ç»“æœ")
    print("=" * 80)
    
    if heavy_result.get("heavy_analysis"):
        analysis = heavy_result["heavy_analysis"]
        synthesis = analysis.get("synthesis", {})
        
        print(f"ğŸ“Š æ€»ä½“ç½®ä¿¡åº¦: {analysis.get('overall_confidence', 0.0):.3f}")
        print(f"ğŸ¤– æœ‰æ•ˆåˆ†æ: {synthesis.get('valid_analyses', 0)}/{synthesis.get('total_agents', 0)} ä¸ªæ™ºèƒ½ä½“")
        
        # æ˜¾ç¤ºå„æ™ºèƒ½ä½“åˆ†æ
        print(f"\nğŸ” å„æ™ºèƒ½ä½“åˆ†æç»“æœ:")
        for i, agent_result in enumerate(analysis.get("agent_analyses", []), 1):
            role = agent_result.get("role", "æœªçŸ¥è§’è‰²")
            confidence = agent_result.get("confidence", 0.0)
            error = agent_result.get("error")
            
            if error:
                print(f"  {i}. âŒ {role}: åˆ†æå¤±è´¥ - {error}")
            else:
                print(f"  {i}. âœ… {role}: ç½®ä¿¡åº¦ {confidence:.3f}")
                
                # æ˜¾ç¤ºå»ºè®®
                recommendations = agent_result.get("recommendations", [])
                if recommendations:
                    print(f"     ğŸ’¡ å»ºè®®: {recommendations[0][:60]}...")
        
        # æ˜¾ç¤ºæœ€ç»ˆå»ºè®®
        final_recommendations = analysis.get('final_recommendations', [])
        if final_recommendations:
            print(f"\nğŸ’¡ æœ€ç»ˆå»ºè®® (å‰5ä¸ª):")
            for i, rec in enumerate(final_recommendations[:5], 1):
                print(f"  {i}. {rec}")
        
        # æ˜¾ç¤ºç»¼åˆæ‘˜è¦
        summary = synthesis.get("summary", "")
        if summary:
            print(f"\nğŸ“‹ ç»¼åˆæ‘˜è¦:")
            print(f"  {summary}")
    
    # æ˜¾ç¤ºSQLå’ŒæŸ¥è¯¢ç»“æœ
    basic_sql = heavy_result.get("basic_sql", "")
    if basic_sql:
        print(f"\nğŸ’» ç”Ÿæˆçš„SQL: {basic_sql}")
    
    query_result = heavy_result.get("query_result")
    if query_result is not None:
        print(f"ğŸ“Š æŸ¥è¯¢ç»“æœ: {query_result}")
    
    query_error = heavy_result.get("query_error")
    if query_error:
        print(f"âŒ æŸ¥è¯¢é”™è¯¯: {query_error}")

def batch_test(assistant, limit):
    """æ‰¹é‡æµ‹è¯•"""
    if not assistant.current_questions:
        print("âŒ æ²¡æœ‰å¯æµ‹è¯•çš„é—®é¢˜")
        return
    
    print(f"âš¡ å¼€å§‹æ‰¹é‡æµ‹è¯• {len(assistant.current_questions)} ä¸ªé—®é¢˜...")
    
    results = []
    success_count = 0
    error_count = 0
    total_confidence = 0.0
    
    for i, question in enumerate(assistant.current_questions):
        print(f"\nå¤„ç†é—®é¢˜ {i+1}/{len(assistant.current_questions)}: {question.question[:50]}...")
        
        try:
            heavy_result = assistant.query_with_heavy(question.question)
            
            if heavy_result.get("heavy_analysis"):
                analysis = heavy_result["heavy_analysis"]
                confidence = analysis.get('overall_confidence', 0.0)
                total_confidence += confidence
                success_count += 1
                
                result = {
                    "question_id": i,
                    "question": question.question,
                    "confidence": confidence,
                    "sql": heavy_result.get("basic_sql", ""),
                    "result": heavy_result.get("query_result"),
                    "status": "success"
                }
                print(f"  âœ… æˆåŠŸ - ç½®ä¿¡åº¦: {confidence:.3f}")
            else:
                error_count += 1
                result = {
                    "question_id": i,
                    "question": question.question,
                    "error": heavy_result.get("heavy_error", "Unknown error"),
                    "status": "error"
                }
                print(f"  âŒ å¤±è´¥")
            
            results.append(result)
            
        except Exception as e:
            error_count += 1
            print(f"  âŒ å¼‚å¸¸: {e}")
            results.append({
                "question_id": i,
                "question": question.question,
                "error": str(e),
                "status": "exception"
            })
    
    # æ˜¾ç¤ºæ‰¹é‡æµ‹è¯•ç»Ÿè®¡
    print(f"\n" + "=" * 60)
    print(f"ğŸ“Š æ‰¹é‡æµ‹è¯•ç»Ÿè®¡ç»“æœ")
    print(f"=" * 60)
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âŒ å¤±è´¥: {error_count}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {success_count/(success_count+error_count)*100:.1f}%")
    
    if success_count > 0:
        avg_confidence = total_confidence / success_count
        print(f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_file = f"heavy_batch_test_results_{len(assistant.current_questions)}.json"
    try:
        import json
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜ç»“æœå¤±è´¥: {e}")

def comparison_test(assistant, limit):
    """å¯¹æ¯”æµ‹è¯•ï¼šæ ‡å‡†æŸ¥è¯¢ vs HeavyæŸ¥è¯¢"""
    if not assistant.current_questions:
        print("âŒ æ²¡æœ‰å¯æµ‹è¯•çš„é—®é¢˜")
        return
    
    print(f"âš–ï¸ å¼€å§‹å¯¹æ¯”æµ‹è¯• {min(limit, len(assistant.current_questions))} ä¸ªé—®é¢˜...")
    
    comparison_results = []
    
    for i, question in enumerate(assistant.current_questions[:limit]):
        print(f"\né—®é¢˜ {i+1}: {question.question[:60]}...")
        
        try:
            # æ ‡å‡†æŸ¥è¯¢
            print("  ğŸ“ æ‰§è¡Œæ ‡å‡†æŸ¥è¯¢...")
            standard_sql = assistant.generate_sql(question.question, question.table_id)
            standard_result = assistant.execute_sql(standard_sql) if standard_sql else "SQLç”Ÿæˆå¤±è´¥"
            
            # HeavyæŸ¥è¯¢
            print("  ğŸ§  æ‰§è¡ŒHeavyæŸ¥è¯¢...")
            heavy_result = assistant.query_with_heavy(question.question)
            heavy_sql = heavy_result.get("basic_sql", "")
            heavy_query_result = heavy_result.get("query_result", "æŸ¥è¯¢å¤±è´¥")
            heavy_confidence = 0.0
            
            if heavy_result.get("heavy_analysis"):
                heavy_confidence = heavy_result["heavy_analysis"].get('overall_confidence', 0.0)
            
            # æ¯”è¾ƒç»“æœ
            results_match = str(standard_result) == str(heavy_query_result)
            sql_match = standard_sql.strip() == heavy_sql.strip()
            
            comparison = {
                "question_id": i,
                "question": question.question,
                "standard_sql": standard_sql,
                "heavy_sql": heavy_sql,
                "standard_result": standard_result,
                "heavy_result": heavy_query_result,
                "heavy_confidence": heavy_confidence,
                "sql_match": sql_match,
                "results_match": results_match,
                "status": "success"
            }
            
            print(f"    SQLåŒ¹é…: {'âœ…' if sql_match else 'âŒ'}")
            print(f"    ç»“æœåŒ¹é…: {'âœ…' if results_match else 'âŒ'}")
            print(f"    Heavyç½®ä¿¡åº¦: {heavy_confidence:.3f}")
            
        except Exception as e:
            print(f"  âŒ å¯¹æ¯”æµ‹è¯•å¼‚å¸¸: {e}")
            comparison = {
                "question_id": i,
                "question": question.question,
                "error": str(e),
                "status": "error"
            }
        
        comparison_results.append(comparison)
    
    # ç»Ÿè®¡å¯¹æ¯”ç»“æœ
    successful_comparisons = [r for r in comparison_results if r.get("status") == "success"]
    sql_matches = sum(1 for r in successful_comparisons if r.get("sql_match", False))
    result_matches = sum(1 for r in successful_comparisons if r.get("results_match", False))
    
    print(f"\n" + "=" * 60)
    print(f"âš–ï¸ å¯¹æ¯”æµ‹è¯•ç»Ÿè®¡")
    print(f"=" * 60)
    print(f"ğŸ“Š æˆåŠŸå¯¹æ¯”: {len(successful_comparisons)}/{len(comparison_results)}")
    
    if successful_comparisons:
        print(f"ğŸ” SQLåŒ¹é…ç‡: {sql_matches}/{len(successful_comparisons)} ({sql_matches/len(successful_comparisons)*100:.1f}%)")
        print(f"ğŸ“Š ç»“æœåŒ¹é…ç‡: {result_matches}/{len(successful_comparisons)} ({result_matches/len(successful_comparisons)*100:.1f}%)")
        
        avg_confidence = sum(r.get("heavy_confidence", 0) for r in successful_comparisons) / len(successful_comparisons)
        print(f"ğŸ¯ Heavyå¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    output_file = f"comparison_test_results_{len(comparison_results)}.json"
    try:
        import json
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(comparison_results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜å¯¹æ¯”ç»“æœå¤±è´¥: {e}")

def validate_prediction(prediction, question_idx, source_file, db_file, temp_predictions_file):
    """éªŒè¯å•ä¸ªé¢„æµ‹ç»“æœ"""
    try:
        # å†™å…¥ä¸´æ—¶é¢„æµ‹æ–‡ä»¶
        with open(temp_predictions_file, 'w', encoding='utf-8') as f:
            import json
            f.write(json.dumps(prediction, ensure_ascii=False) + '\n')
        
        # åˆ›å»ºéªŒè¯å™¨
        from wikisql_validator import WikiSQLValidator
        validator = WikiSQLValidator(source_file, db_file, temp_predictions_file)
        
        # æ‰§è¡ŒéªŒè¯
        summary = validator.evaluate()
        
        # è¿”å›éªŒè¯ç»“æœ
        is_correct = summary['correct_answers'] > 0
        return {
            "is_correct": is_correct,
            "accuracy": summary['accuracy'],
            "error_info": summary.get('error_info', ''),
            "total_questions": summary['total_questions']
        }
        
    except Exception as e:
        return {
            "is_correct": False,
            "accuracy": 0.0,
            "error_info": f"éªŒè¯å¤±è´¥: {str(e)}",
            "total_questions": 1
        }

def single_question_test_with_validation(assistant, source_file, db_file, temp_predictions_file, use_heavy=True):
    """å¸¦éªŒè¯çš„å•ä¸ªé—®é¢˜è¯¦ç»†æµ‹è¯•"""
    if not assistant.current_questions:
        print("âŒ æ²¡æœ‰å¯æµ‹è¯•çš„é—®é¢˜")
        return
    
    question = assistant.current_questions[0]
    print(f"\nğŸ“ æµ‹è¯•é—®é¢˜: {question.question}")
    print(f"ğŸ“‹ è¡¨æ ¼ID: {question.table_id}")
    
    try:
        if use_heavy:
            # HeavyæŸ¥è¯¢
            print("\nğŸ§  æ‰§è¡ŒHeavyåˆ†æ...")
            heavy_result = assistant.query_with_heavy(question.question)
            
            # ç”ŸæˆWikiSQLæ ¼å¼é¢„æµ‹
            if heavy_result.get("basic_sql"):
                wikisql_prediction = assistant._parse_sql_to_wikisql_format(
                    heavy_result["basic_sql"], question
                )
                if wikisql_prediction:
                    prediction = {"query": wikisql_prediction}
                else:
                    prediction = {"error": "SQLè§£æå¤±è´¥"}
            else:
                prediction = {"error": "SQLç”Ÿæˆå¤±è´¥"}
            
            # æ˜¾ç¤ºHeavyåˆ†æç»“æœ
            if heavy_result.get("heavy_analysis"):
                analysis = heavy_result["heavy_analysis"]
                print(f"ğŸ“Š Heavyç½®ä¿¡åº¦: {analysis.get('overall_confidence', 0.0):.3f}")
                print(f"ğŸ¤– æœ‰æ•ˆæ™ºèƒ½ä½“: {analysis.get('synthesis', {}).get('valid_analyses', 0)}/4")
        else:
            # æ ‡å‡†æŸ¥è¯¢
            print("\nğŸ“ æ‰§è¡Œæ ‡å‡†æŸ¥è¯¢...")
            prediction = assistant.generate_wikisql_prediction(0)
        
        # éªŒè¯ç»“æœ
        print("\nğŸ” éªŒè¯é¢„æµ‹ç»“æœ...")
        validation_result = validate_prediction(prediction, 0, source_file, db_file, temp_predictions_file)
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ¯ éªŒè¯ç»“æœ")
        print("=" * 60)
        print(f"âœ… æ­£ç¡®æ€§: {'æ­£ç¡®' if validation_result['is_correct'] else 'é”™è¯¯'}")
        print(f"ğŸ“Š å‡†ç¡®ç‡: {validation_result['accuracy']:.3f}")
        
        if not validation_result['is_correct']:
            print(f"âŒ é”™è¯¯ä¿¡æ¯: {validation_result['error_info']}")
        
        # æ˜¾ç¤ºé¢„æµ‹å†…å®¹
        print(f"\nğŸ’» é¢„æµ‹ç»“æœ:")
        if "query" in prediction:
            query = prediction["query"]
            print(f"  SELECT: col{query.get('sel', 0)}")
            print(f"  AGG: {query.get('agg', 0)}")
            print(f"  CONDITIONS: {query.get('conds', [])}")
        else:
            print(f"  é”™è¯¯: {prediction.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def batch_test_with_validation(assistant, limit, source_file, db_file, temp_predictions_file, use_heavy=True):
    """å¸¦éªŒè¯çš„æ‰¹é‡æµ‹è¯•"""
    if not assistant.current_questions:
        print("âŒ æ²¡æœ‰å¯æµ‹è¯•çš„é—®é¢˜")
        return
    
    mode_name = "Heavy" if use_heavy else "æ ‡å‡†"
    print(f"âš¡ å¼€å§‹{mode_name}æ‰¹é‡æµ‹è¯• {len(assistant.current_questions)} ä¸ªé—®é¢˜...")
    
    predictions = []
    results = []
    correct_count = 0
    error_count = 0
    
    for i, question in enumerate(assistant.current_questions):
        print(f"\nå¤„ç†é—®é¢˜ {i+1}/{len(assistant.current_questions)}: {question.question[:50]}...")
        
        try:
            if use_heavy:
                # HeavyæŸ¥è¯¢
                heavy_result = assistant.query_with_heavy(question.question)
                if heavy_result.get("basic_sql"):
                    wikisql_prediction = assistant._parse_sql_to_wikisql_format(
                        heavy_result["basic_sql"], question
                    )
                    if wikisql_prediction:
                        prediction = {"query": wikisql_prediction}
                        confidence = heavy_result.get("heavy_analysis", {}).get('overall_confidence', 0.0)
                    else:
                        prediction = {"error": "SQLè§£æå¤±è´¥"}
                        confidence = 0.0
                else:
                    prediction = {"error": "SQLç”Ÿæˆå¤±è´¥"}
                    confidence = 0.0
            else:
                # æ ‡å‡†æŸ¥è¯¢
                prediction = assistant.generate_wikisql_prediction(i)
                confidence = 1.0  # æ ‡å‡†æŸ¥è¯¢æ²¡æœ‰ç½®ä¿¡åº¦
            
            predictions.append(prediction)
            
            # éªŒè¯ç»“æœ
            validation_result = validate_prediction(prediction, i, source_file, db_file, temp_predictions_file)
            
            if validation_result['is_correct']:
                correct_count += 1
                print(f"  âœ… æ­£ç¡®")
            else:
                error_count += 1
                print(f"  âŒ é”™è¯¯")
            
            result = {
                "question_id": i,
                "question": question.question,
                "prediction": prediction,
                "is_correct": validation_result['is_correct'],
                "confidence": confidence if use_heavy else None,
                "validation_accuracy": validation_result['accuracy']
            }
            results.append(result)
            
        except Exception as e:
            error_count += 1
            print(f"  âŒ å¼‚å¸¸: {e}")
            predictions.append({"error": str(e)})
            results.append({
                "question_id": i,
                "question": question.question,
                "error": str(e),
                "is_correct": False
            })
    
    # ä¿å­˜æ‰€æœ‰é¢„æµ‹åˆ°æ–‡ä»¶è¿›è¡Œæœ€ç»ˆéªŒè¯
    final_predictions_file = f"{mode_name.lower()}_predictions_{len(assistant.current_questions)}.jsonl"
    with open(final_predictions_file, 'w', encoding='utf-8') as f:
        for prediction in predictions:
            import json
            f.write(json.dumps(prediction, ensure_ascii=False) + '\n')
    
    # æœ€ç»ˆéªŒè¯
    print(f"\nğŸ” æ‰§è¡Œæœ€ç»ˆæ‰¹é‡éªŒè¯...")
    try:
        from wikisql_validator import WikiSQLValidator
        validator = WikiSQLValidator(source_file, db_file, final_predictions_file)
        final_summary = validator.evaluate()
        
        print(f"\n" + "=" * 60)
        print(f"ğŸ“Š {mode_name}æ‰¹é‡æµ‹è¯•æœ€ç»ˆç»“æœ")
        print(f"=" * 60)
        print(f"âœ… æ­£ç¡®ç­”æ¡ˆ: {final_summary['correct_answers']}")
        print(f"âŒ é”™è¯¯ç­”æ¡ˆ: {final_summary['errors']}")
        print(f"ğŸ“ˆ æœ€ç»ˆå‡†ç¡®ç‡: {final_summary['accuracy']:.3f} ({final_summary['accuracy']*100:.1f}%)")
        print(f"ğŸ“Š æ€»é—®é¢˜æ•°: {final_summary['total_questions']}")
        
        if use_heavy and results:
            # è®¡ç®—Heavyæ¨¡å¼çš„å¹³å‡ç½®ä¿¡åº¦
            heavy_results = [r for r in results if r.get('confidence') is not None]
            if heavy_results:
                avg_confidence = sum(r['confidence'] for r in heavy_results) / len(heavy_results)
                print(f"ğŸ¯ å¹³å‡Heavyç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
    except Exception as e:
        print(f"âŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_file = f"{mode_name.lower()}_batch_results_{len(assistant.current_questions)}.json"
    try:
        import json
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        print(f"ğŸ’¾ é¢„æµ‹æ–‡ä»¶å·²ä¿å­˜åˆ°: {final_predictions_file}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜ç»“æœå¤±è´¥: {e}")

def comparison_test_with_validation(assistant, limit, source_file, db_file, temp_predictions_file):
    """å¸¦éªŒè¯çš„å¯¹æ¯”æµ‹è¯•"""
    if not assistant.current_questions:
        print("âŒ æ²¡æœ‰å¯æµ‹è¯•çš„é—®é¢˜")
        return
    
    print(f"âš–ï¸ å¼€å§‹å¯¹æ¯”æµ‹è¯• {min(limit, len(assistant.current_questions))} ä¸ªé—®é¢˜...")
    
    standard_predictions = []
    heavy_predictions = []
    comparison_results = []
    
    for i, question in enumerate(assistant.current_questions[:limit]):
        print(f"\né—®é¢˜ {i+1}: {question.question[:60]}...")
        
        try:
            # æ ‡å‡†æŸ¥è¯¢
            print("  ğŸ“ æ‰§è¡Œæ ‡å‡†æŸ¥è¯¢...")
            standard_prediction = assistant.generate_wikisql_prediction(i)
            standard_predictions.append(standard_prediction)
            
            # éªŒè¯æ ‡å‡†æŸ¥è¯¢
            standard_validation = validate_prediction(standard_prediction, i, source_file, db_file, temp_predictions_file)
            
            # HeavyæŸ¥è¯¢
            print("  ğŸ§  æ‰§è¡ŒHeavyæŸ¥è¯¢...")
            heavy_result = assistant.query_with_heavy(question.question)
            
            if heavy_result.get("basic_sql"):
                wikisql_prediction = assistant._parse_sql_to_wikisql_format(
                    heavy_result["basic_sql"], question
                )
                if wikisql_prediction:
                    heavy_prediction = {"query": wikisql_prediction}
                else:
                    heavy_prediction = {"error": "SQLè§£æå¤±è´¥"}
            else:
                heavy_prediction = {"error": "SQLç”Ÿæˆå¤±è´¥"}
            
            heavy_predictions.append(heavy_prediction)
            
            # éªŒè¯HeavyæŸ¥è¯¢
            heavy_validation = validate_prediction(heavy_prediction, i, source_file, db_file, temp_predictions_file)
            
            # è·å–Heavyç½®ä¿¡åº¦
            heavy_confidence = 0.0
            if heavy_result.get("heavy_analysis"):
                heavy_confidence = heavy_result["heavy_analysis"].get('overall_confidence', 0.0)
            
            comparison = {
                "question_id": i,
                "question": question.question,
                "standard_prediction": standard_prediction,
                "heavy_prediction": heavy_prediction,
                "standard_correct": standard_validation['is_correct'],
                "heavy_correct": heavy_validation['is_correct'],
                "heavy_confidence": heavy_confidence,
                "standard_accuracy": standard_validation['accuracy'],
                "heavy_accuracy": heavy_validation['accuracy']
            }
            
            print(f"    æ ‡å‡†æŸ¥è¯¢: {'âœ…' if standard_validation['is_correct'] else 'âŒ'}")
            print(f"    HeavyæŸ¥è¯¢: {'âœ…' if heavy_validation['is_correct'] else 'âŒ'} (ç½®ä¿¡åº¦: {heavy_confidence:.3f})")
            
        except Exception as e:
            print(f"  âŒ å¯¹æ¯”æµ‹è¯•å¼‚å¸¸: {e}")
            comparison = {
                "question_id": i,
                "question": question.question,
                "error": str(e)
            }
        
        comparison_results.append(comparison)
    
    # ä¿å­˜é¢„æµ‹æ–‡ä»¶å¹¶è¿›è¡Œæœ€ç»ˆéªŒè¯
    standard_file = f"standard_predictions_comparison_{limit}.jsonl"
    heavy_file = f"heavy_predictions_comparison_{limit}.jsonl"
    
    with open(standard_file, 'w', encoding='utf-8') as f:
        for pred in standard_predictions:
            import json
            f.write(json.dumps(pred, ensure_ascii=False) + '\n')
    
    with open(heavy_file, 'w', encoding='utf-8') as f:
        for pred in heavy_predictions:
            import json
            f.write(json.dumps(pred, ensure_ascii=False) + '\n')
    
    # æœ€ç»ˆéªŒè¯
    print(f"\nğŸ” æ‰§è¡Œæœ€ç»ˆå¯¹æ¯”éªŒè¯...")
    try:
        from wikisql_validator import WikiSQLValidator
        
        # éªŒè¯æ ‡å‡†æŸ¥è¯¢
        standard_validator = WikiSQLValidator(source_file, db_file, standard_file)
        standard_summary = standard_validator.evaluate()
        
        # éªŒè¯HeavyæŸ¥è¯¢
        heavy_validator = WikiSQLValidator(source_file, db_file, heavy_file)
        heavy_summary = heavy_validator.evaluate()
        
        print(f"\n" + "=" * 60)
        print(f"âš–ï¸ å¯¹æ¯”æµ‹è¯•æœ€ç»ˆç»“æœ")
        print(f"=" * 60)
        print(f"ğŸ“ æ ‡å‡†æŸ¥è¯¢å‡†ç¡®ç‡: {standard_summary['accuracy']:.3f} ({standard_summary['accuracy']*100:.1f}%)")
        print(f"ğŸ§  HeavyæŸ¥è¯¢å‡†ç¡®ç‡: {heavy_summary['accuracy']:.3f} ({heavy_summary['accuracy']*100:.1f}%)")
        
        improvement = heavy_summary['accuracy'] - standard_summary['accuracy']
        print(f"ğŸ“ˆ Heavyæ”¹è¿›: {improvement:+.3f} ({improvement*100:+.1f}%)")
        
        # Heavyç½®ä¿¡åº¦ç»Ÿè®¡
        successful_comparisons = [r for r in comparison_results if 'error' not in r]
        if successful_comparisons:
            avg_confidence = sum(r.get('heavy_confidence', 0) for r in successful_comparisons) / len(successful_comparisons)
            print(f"ğŸ¯ Heavyå¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
    except Exception as e:
        print(f"âŒ æœ€ç»ˆéªŒè¯å¤±è´¥: {e}")
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    output_file = f"comparison_results_validated_{limit}.json"
    try:
        import json
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(comparison_results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        print(f"ğŸ’¾ æ ‡å‡†é¢„æµ‹æ–‡ä»¶: {standard_file}")
        print(f"ğŸ’¾ Heavyé¢„æµ‹æ–‡ä»¶: {heavy_file}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜å¯¹æ¯”ç»“æœå¤±è´¥: {e}")

def main():
    """æµ‹è¯•WikiSQL Heavyé›†æˆ"""
    print("ğŸš€ WikiSQL Heavy Integration æµ‹è¯•")
    print("=" * 60)
    
    # è·å–APIå¯†é’¥
    api_key = input("è¯·è¾“å…¥ä½ çš„Google AI Studio APIå¯†é’¥: ").strip()
    if not api_key:
        print("âŒ éœ€è¦æä¾›APIå¯†é’¥")
        return
    
    # é¦–å…ˆé€‰æ‹©æŸ¥è¯¢æ¨¡å¼
    print("\nğŸ¯ é€‰æ‹©æŸ¥è¯¢æ¨¡å¼:")
    print("1. æ ‡å‡†LLMæŸ¥è¯¢ (å•ä¸€LLMç”ŸæˆSQL)")
    print("2. Heavyå¤šæ™ºèƒ½ä½“æŸ¥è¯¢ (4ä¸ªæ™ºèƒ½ä½“åä½œåˆ†æ)")
    print("3. å¯¹æ¯”æ¨¡å¼ (æ ‡å‡† vs Heavy å¯¹æ¯”æµ‹è¯•)")
    
    query_mode = input("è¯·é€‰æ‹©æŸ¥è¯¢æ¨¡å¼ (1/2/3, é»˜è®¤ 1): ").strip()
    
    if query_mode == "2":
        mode_type = "heavy"
        print("âœ… å·²é€‰æ‹©: Heavyå¤šæ™ºèƒ½ä½“æŸ¥è¯¢")
    elif query_mode == "3":
        mode_type = "comparison"
        print("âœ… å·²é€‰æ‹©: å¯¹æ¯”æ¨¡å¼")
    else:
        mode_type = "standard"
        print("âœ… å·²é€‰æ‹©: æ ‡å‡†LLMæŸ¥è¯¢")
    
    # é€‰æ‹©æ•°æ®åˆ†å‰²
    print("\nğŸ“‹ é€‰æ‹©æ•°æ®åˆ†å‰²:")
    print("1. dev (éªŒè¯é›†, æ¨è)")
    print("2. test (æµ‹è¯•é›†)")
    print("3. train (è®­ç»ƒé›†)")
    
    split_choice = input("è¯·é€‰æ‹©æ•°æ®åˆ†å‰² (1/2/3, é»˜è®¤ 1): ").strip()
    if split_choice == "2":
        split = "test"
    elif split_choice == "3":
        split = "train"
    else:
        split = "dev"
    
    print(f"âœ… å·²é€‰æ‹©æ•°æ®åˆ†å‰²: {split}")
    
    # é€‰æ‹©æµ‹è¯•æ•°æ®é‡
    print(f"\nğŸ“‹ é€‰æ‹©æµ‹è¯•æ•°æ®é‡:")
    print("1. å°è§„æ¨¡æµ‹è¯• (3 ä¸ªé—®é¢˜)")
    print("2. ä¸­ç­‰æµ‹è¯• (10 ä¸ªé—®é¢˜)")
    print("3. å¤§è§„æ¨¡æµ‹è¯• (50 ä¸ªé—®é¢˜)")
    print("4. è‡ªå®šä¹‰æ•°é‡")
    
    limit_choice = input("è¯·é€‰æ‹©æµ‹è¯•è§„æ¨¡ (1/2/3/4, é»˜è®¤ 1): ").strip()
    
    if limit_choice == "2":
        limit = 10
    elif limit_choice == "3":
        limit = 50
    elif limit_choice == "4":
        custom_limit = input("è¯·è¾“å…¥è‡ªå®šä¹‰æ•°é‡: ").strip()
        try:
            limit = int(custom_limit)
            if limit <= 0:
                print("âŒ æ•°é‡å¿…é¡»å¤§äº0ï¼Œä½¿ç”¨é»˜è®¤å€¼3")
                limit = 3
        except ValueError:
            print("âŒ è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼3")
            limit = 3
    else:
        limit = 3
    
    print(f"âœ… å·²é€‰æ‹©æµ‹è¯•æ•°é‡: {limit} ä¸ªé—®é¢˜")
    
    # æ ¹æ®æŸ¥è¯¢æ¨¡å¼é€‰æ‹©æµ‹è¯•æ–¹å¼
    if mode_type == "comparison":
        test_mode = "comparison"
        print(f"\nğŸ“‹ å¯¹æ¯”æ¨¡å¼å°†åŒæ—¶æµ‹è¯•æ ‡å‡†æŸ¥è¯¢å’ŒHeavyæŸ¥è¯¢")
    else:
        print(f"\nğŸ“‹ é€‰æ‹©æµ‹è¯•æ–¹å¼:")
        print("1. å•ä¸ªé—®é¢˜è¯¦ç»†æµ‹è¯• (æ˜¾ç¤ºå®Œæ•´åˆ†æè¿‡ç¨‹)")
        print("2. æ‰¹é‡æµ‹è¯• (å¿«é€Ÿå¤„ç†å¤šä¸ªé—®é¢˜)")
        
        test_choice = input("è¯·é€‰æ‹©æµ‹è¯•æ–¹å¼ (1/2, é»˜è®¤ 1): ").strip()
        test_mode = "batch" if test_choice == "2" else "single"
    
    try:
        # æ ¹æ®æ¨¡å¼åˆå§‹åŒ–åŠ©æ‰‹
        if mode_type == "heavy" or mode_type == "comparison":
            print(f"\nğŸ”§ åˆå§‹åŒ–WikiSQL HeavyåŠ©æ‰‹...")
            assistant = WikiSQLDirectLLMHeavy(api_key)
        else:
            print(f"\nğŸ”§ åˆå§‹åŒ–æ ‡å‡†WikiSQLåŠ©æ‰‹...")
            from wikisql_llm_direct import WikiSQLDirectLLM
            assistant = WikiSQLDirectLLM(api_key)
        
        # åŠ è½½æ•°æ®é›†
        print(f"ğŸ“¥ åŠ è½½WikiSQLæ•°æ®é›† ({split}, é™åˆ¶: {limit})...")
        assistant.load_wikisql_dataset(split, limit)
        
        # åˆå§‹åŒ–WikiSQLéªŒè¯å™¨
        print(f"ğŸ”§ åˆå§‹åŒ–WikiSQLéªŒè¯å™¨...")
        from wikisql_validator import WikiSQLValidator
        
        # æ„å»ºéªŒè¯å™¨æ‰€éœ€çš„æ–‡ä»¶è·¯å¾„
        wikisql_data_path = assistant.data_loader.local_wikisql_path or "WikiSQL"
        source_file = f"{wikisql_data_path}/data/{split}.jsonl"
        db_file = f"{wikisql_data_path}/data/{split}.db"
        
        # åˆ›å»ºä¸´æ—¶é¢„æµ‹æ–‡ä»¶ç”¨äºéªŒè¯
        temp_predictions_file = f"temp_predictions_{split}.jsonl"
        
        # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
        info = assistant.get_dataset_info()
        print(f"\nğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"  - é—®é¢˜æ•°é‡: {info['questions_count']}")
        print(f"  - è¡¨æ ¼æ•°é‡: {info['tables_count']}")
        print(f"  - æ•°æ®åº“è¡¨æ ¼: {info['db_tables_count']}")
        
        # æ ¹æ®é€‰æ‹©çš„æ¨¡å¼å’Œæµ‹è¯•æ–¹å¼æ‰§è¡Œæµ‹è¯•
        if mode_type == "comparison":
            # å¯¹æ¯”æ¨¡å¼
            print(f"\nâš–ï¸ æ‰§è¡Œå¯¹æ¯”æµ‹è¯•...")
            comparison_test_with_validation(assistant, min(10, limit), source_file, db_file, temp_predictions_file)
            
        elif test_mode == "batch":
            # æ‰¹é‡æµ‹è¯•
            print(f"\nâš¡ æ‰§è¡Œæ‰¹é‡æµ‹è¯•...")
            if mode_type == "heavy":
                batch_test_with_validation(assistant, limit, source_file, db_file, temp_predictions_file, use_heavy=True)
            else:
                batch_test_with_validation(assistant, limit, source_file, db_file, temp_predictions_file, use_heavy=False)
                
        else:
            # å•ä¸ªé—®é¢˜è¯¦ç»†æµ‹è¯•
            print(f"\nğŸ” æ‰§è¡Œå•ä¸ªé—®é¢˜è¯¦ç»†æµ‹è¯•...")
            if mode_type == "heavy":
                single_question_test_with_validation(assistant, source_file, db_file, temp_predictions_file, use_heavy=True)
            else:
                single_question_test_with_validation(assistant, source_file, db_file, temp_predictions_file, use_heavy=False)
        
        print("\nâœ… Heavyé›†æˆæµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()