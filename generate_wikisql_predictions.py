#!/usr/bin/env python3
"""
WikiSQLæ™ºèƒ½æŸ¥è¯¢ç³»ç»Ÿä¸»ç¨‹åº
æ”¯æŒåŸºç¡€æŸ¥è¯¢å’ŒHeavyå¤šæ™ºèƒ½ä½“åˆ†æ
"""

import os
import sys
import subprocess
import json
from pathlib import Path

def main():
    """Main function - WikiSQL complete functionality entry point"""
    print("ğŸš€ WikiSQL Intelligent Query System")
    print("=" * 60)
    print("Supporting basic queries and Heavy multi-agent analysis")
    print("=" * 60)
    
    # Step 1: Get API key
    print("\nğŸ“‹ Step 1: API Key Configuration")
    api_key = input("Please enter your API key: ").strip()
    if not api_key:
        print("âŒ API key is required")
        return
    print("âœ… API key configured")
    
    # Step 2: Select model
    print("\nğŸ“‹ Step 2: Model Selection")
    print("1. Gemini 2.5 Flash (Recommended, fast)")
    print("2. Gemma 3 27B IT (High precision)")
    
    model_choice = input("Please select model (1/2, default 1): ").strip()
    if model_choice == "2":
        selected_model = "gemma-3-27b-it"
        print("âœ… Selected: Gemma 3 27B IT")
    else:
        selected_model = "gemini-2.5-flash"
        print("âœ… Selected: Gemini 2.5 Flash")
    
    # Step 3: Select data split
    print("\nğŸ“‹ Step 3: Data Split Selection")
    print("1. dev (validation set, recommended)")
    print("2. test (test set)")
    print("3. train (training set)")
    
    split_choice = input("Please select data split (1/2/3, default 1): ").strip()
    if split_choice == "2":
        split = "test"
    elif split_choice == "3":
        split = "train"
    else:
        split = "dev"
    
    print(f"âœ… Selected data split: {split}")
    
    # Step 4: Set question limit
    print(f"\nğŸ“‹ Step 4: Question Limit Configuration")
    limit_input = input("Please enter number of questions to process (default 100): ").strip()
    try:
        limit = int(limit_input) if limit_input else 100
    except ValueError:
        limit = 100
    
    print(f"âœ… Question limit: {limit}")
    
    # Step 5: Select query mode
    print(f"\nğŸ“‹ Step 5: Query Mode Selection")
    print("1. Standard Query (æ ‡å‡†æŸ¥è¯¢, å¿«é€Ÿ, ~86% å‡†ç¡®ç‡)")
    print("2. Heavy Query (4ä¸ªå¹¶è¡Œæ™ºèƒ½ä½“æ·±åº¦åˆ†æ, ~84% å‡†ç¡®ç‡)")
    
    query_mode = input("è¯·é€‰æ‹©æŸ¥è¯¢æ¨¡å¼ (1/2, é»˜è®¤ 1): ").strip()
    use_heavy = query_mode == "2"
    
    if use_heavy:
        print("âœ… å·²é€‰æ‹©: Heavyå¤šæ™ºèƒ½ä½“æŸ¥è¯¢")
        print("   - ä½¿ç”¨4ä¸ªä¸“é—¨æ™ºèƒ½ä½“è¿›è¡Œæ·±åº¦åˆ†æ")
        print("   - SQLä¸“å®¶ã€æ•°æ®åˆ†æå¸ˆã€æ€§èƒ½ä¼˜åŒ–å¸ˆã€ç»“æœéªŒè¯å¸ˆ")
    else:
        print("âœ… å·²é€‰æ‹©: æ ‡å‡†æŸ¥è¯¢")
    
    # Detect local WikiSQL data
    print(f"\nğŸ” Detecting local WikiSQL data...")
    wikisql_path = None
    possible_paths = ["WikiSQL", "../WikiSQL", "./WikiSQL"]
    
    for path in possible_paths:
        path_obj = Path(path)
        if (path_obj.exists() and 
            (path_obj / "data").exists() and
            (path_obj / "data" / f"{split}.jsonl").exists()):
            wikisql_path = str(path_obj)
            print(f"âœ… Found local WikiSQL: {wikisql_path}")
            break
    
    if not wikisql_path:
        print("âŒ Local WikiSQL data not found")
        print("Please ensure WikiSQL directory is in current directory")
        return
    
    try:
        # Initialize WikiSQL query assistant
        print(f"\nğŸ”§ åˆå§‹åŒ–WikiSQLæŸ¥è¯¢åŠ©æ‰‹...")
        
        if use_heavy:
            print("ğŸ§  å¯ç”¨Heavyå¤šæ™ºèƒ½ä½“æ¨¡å¼...")
            from wikisql_heavy_simple import WikiSQLDirectLLMSimpleHeavy
            assistant = WikiSQLDirectLLMSimpleHeavy(api_key)
            print("âœ… Heavyæ¨¡å¼å·²å¯ç”¨ - 4ä¸ªä¸“é—¨æ™ºèƒ½ä½“å¹¶è¡Œåˆ†æ")
        else:
            print("âš¡ å¯ç”¨æ ‡å‡†æŸ¥è¯¢æ¨¡å¼...")
            from wikisql_llm_direct import WikiSQLDirectLLM
            assistant = WikiSQLDirectLLM(api_key)
            print("âœ… æ ‡å‡†æ¨¡å¼å·²å¯ç”¨")
        
        # Set local data path
        assistant.data_loader.local_wikisql_path = Path(wikisql_path)
        
        # If different model selected, reconfigure
        if selected_model != "gemini-2.5-flash":
            print(f"ğŸ”„ Switching to {selected_model} model...")
            from langchain_openai import ChatOpenAI
            
            base_url = "https://okjtgbhgemzb.eu-central-1.clawcloudrun.com"
            new_llm = ChatOpenAI(
                model=selected_model,
                temperature=0,
                base_url=f"{base_url}/v1",
                request_timeout=30,
                verbose=True
            )
            
            assistant.llm = new_llm
            
            # If Heavy mode, reinitialize Heavy Orchestrator with new model
            if use_heavy and hasattr(assistant, 'heavy_orchestrator'):
                print(f"ğŸ”„ é‡æ–°åˆå§‹åŒ–Heavyæ™ºèƒ½ä½“ä½¿ç”¨ {selected_model} æ¨¡å‹...")
                try:
                    from wikisql_heavy_simple import SimpleHeavyOrchestrator
                    assistant.heavy_orchestrator = SimpleHeavyOrchestrator(api_key, selected_model)
                    print(f"âœ… Heavyæ™ºèƒ½ä½“å·²åˆ‡æ¢åˆ° {selected_model} æ¨¡å‹")
                except Exception as e:
                    print(f"âš ï¸ Heavyæ™ºèƒ½ä½“æ¨¡å‹åˆ‡æ¢å¤±è´¥: {e}")
                    assistant.heavy_enabled = False
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        mode_suffix = "heavy" if use_heavy else "normal"
        output_file = f"predictions_{split}_{limit}_{selected_model.replace('-', '_')}_{mode_suffix}.jsonl"
        
        # åŠ è½½æ•°æ®é›†
        print(f"\nğŸ“¥ åŠ è½½WikiSQLæ•°æ®é›† ({split}, é™åˆ¶: {limit})...")
        assistant.load_wikisql_dataset(split, limit, force_download=False)
        
        # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
        info = assistant.get_dataset_info()
        print(f"\nğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"  - é—®é¢˜æ•°é‡: {info['questions_count']}")
        print(f"  - è¡¨æ ¼æ•°é‡: {info['tables_count']}")
        print(f"  - æ•°æ®åº“è¡¨æ ¼: {info['db_tables_count']}")
        
        # ç”Ÿæˆé¢„æµ‹
        print(f"\nğŸ¯ å¼€å§‹ç”Ÿæˆé¢„æµ‹...")
        print(f"æ¨¡å¼: {'Heavyå¤šæ™ºèƒ½ä½“åˆ†æ' if use_heavy else 'æ ‡å‡†æŸ¥è¯¢'}")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
        
        predictions = []
        
        for i, question in enumerate(assistant.current_questions):
            print(f"\nå¤„ç†é—®é¢˜ {i+1}/{len(assistant.current_questions)}:")
            print(f"é—®é¢˜: {question.question[:80]}...")
            
            try:
                if use_heavy:
                    # Heavy mode: Use multi-agent analysis
                    print("ğŸ§  å¼€å§‹Heavyå¤šæ™ºèƒ½ä½“åˆ†æ...")
                    
                    heavy_result = assistant.generate_sql_with_heavy_analysis(
                        question.question, 
                        question.table_id
                    )
                    
                    if heavy_result.get("heavy_analysis"):
                        analysis = heavy_result["heavy_analysis"]
                        confidence = analysis.get("overall_confidence", 0.0)
                        print(f"   âœ… Heavyåˆ†æå®Œæˆï¼Œç½®ä¿¡åº¦: {confidence:.3f}")
                        
                        # ä½¿ç”¨Heavyåˆ†ææ”¹è¿›çš„SQLï¼Œå¦‚æœæ²¡æœ‰æ”¹è¿›åˆ™ä½¿ç”¨åŸºç¡€SQL
                        improved_sql = analysis.get("improved_sql", "")
                        basic_sql = heavy_result.get("basic_sql", "")
                        final_sql = improved_sql if improved_sql and improved_sql != basic_sql else basic_sql
                        
                        if final_sql:
                            if improved_sql and improved_sql != basic_sql:
                                print(f"   ğŸ”§ ä½¿ç”¨Heavyæ”¹è¿›çš„SQL: {improved_sql[:50]}...")
                            else:
                                print(f"   ğŸ“ ä½¿ç”¨åŸºç¡€SQL: {basic_sql[:50]}...")
                            
                            wikisql_query = assistant._parse_sql_to_wikisql_format(final_sql, question)
                            if wikisql_query:
                                prediction = {
                                    "query": wikisql_query,
                                    "heavy_confidence": confidence,
                                    "heavy_agents": analysis.get("synthesis", {}).get("valid_analyses", 0),
                                    "heavy_improved": improved_sql != basic_sql if improved_sql else False,
                                    "original_sql": basic_sql,
                                    "final_sql": final_sql
                                }
                            else:
                                prediction = {"error": f"SQL parsing failed: {final_sql}"}
                        else:
                            prediction = {"error": "SQL generation failed"}
                    else:
                        prediction = {"error": "Heavy analysis failed"}
                else:
                    # Standard mode: Standard prediction generation
                    prediction = assistant.generate_wikisql_prediction(i)
                    print(f"   âœ… æ ‡å‡†æŸ¥è¯¢å®Œæˆ")
                
                predictions.append(prediction)
                
                # Display progress
                if (i + 1) % 5 == 0:
                    success_count = len([p for p in predictions if "error" not in p])
                    print(f"ğŸ“Š Progress: {i + 1}/{len(assistant.current_questions)}, Success: {success_count}")
                    
            except Exception as e:
                print(f"   âŒ Processing failed: {e}")
                predictions.append({"error": str(e)})
        
        # Save prediction results
        print(f"\nğŸ’¾ Saving prediction results to: {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            for prediction in predictions:
                f.write(json.dumps(prediction, ensure_ascii=False) + '\n')
        
        result_file = output_file
        
        if result_file:
            print(f"âœ… Prediction file generated successfully: {result_file}")
            
            # 7. Try running official evaluator
            print(f"\nğŸ” Attempting to run official evaluator...")
            
            # Use confirmed existing paths
            evaluate_script = Path("WikiSQL") / "evaluate.py"
            source_file = Path("WikiSQL") / "data" / f"{split}.jsonl"
            db_file = Path("WikiSQL") / "data" / f"{split}.db"
            predictions_file = Path(result_file).absolute()
            
            print(f"ğŸ“ Checking files:")
            print(f"  evaluate.py: {'âœ…' if evaluate_script.exists() else 'âŒ'} {evaluate_script}")
            print(f"  {split}.jsonl: {'âœ…' if source_file.exists() else 'âŒ'} {source_file}")
            print(f"  {split}.db: {'âœ…' if db_file.exists() else 'âŒ'} {db_file}")
            print(f"  Prediction file: {'âœ…' if predictions_file.exists() else 'âŒ'} {predictions_file}")
            
            if evaluate_script.exists() and source_file.exists() and db_file.exists():
                try:
                    cmd = [
                        sys.executable,
                        str(evaluate_script.absolute()),
                        str(source_file.absolute()),
                        str(db_file.absolute()),
                        str(predictions_file)
                    ]
                    
                    print(f"ğŸš€ Running command: {' '.join(cmd)}")
                    
                    result = subprocess.run(
                        cmd,
                        capture_output=True,
                        text=True,
                        timeout=300,
                        encoding='utf-8'
                    )
                    
                    if result.returncode == 0:
                        print("âœ… Official evaluator ran successfully!")
                        print("ğŸ“Š Evaluation results:")
                        print(result.stdout)
                    else:
                        print(f"âš ï¸ Official evaluator failed:")
                        print(f"Error output: {result.stderr}")
                        
                        # Use custom validator as fallback
                        print(f"\nğŸ”„ Using custom validator as fallback...")
                        print(f"Run command: python run_validation.py")
                        
                except subprocess.TimeoutExpired:
                    print("âš ï¸ Official evaluator timed out")
                    print(f"ğŸ’¡ Can run manually: python run_validation.py")
                except Exception as e:
                    print(f"âš ï¸ Failed to run official evaluator: {e}")
                    print(f"ğŸ’¡ Can run manually: python run_validation.py")
            else:
                print(f"âš ï¸ Missing required evaluation files:")
                print(f"ğŸ’¡ Can use custom validator: python run_validation.py")
            
            # 8. Usage instructions
            print(f"\nğŸ’¡ Usage instructions:")
            print(f"Prediction file: {result_file}")
            print(f"Format: One JSON object per line")
            print(f"Success: {{\"query\": {{\"sel\": 0, \"agg\": 0, \"conds\": []}}}}")
            print(f"Failure: {{\"error\": \"error message\"}}")
            
            if wikisql_path:
                print(f"\nManual evaluation command:")
                print(f"cd {wikisql_path}")
                abs_result_path = Path(result_file).absolute()
                print(f"python evaluate.py data/{split}.jsonl data/{split}.db \"{abs_result_path}\"")
        else:
            print("âŒ Prediction file generation failed")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()