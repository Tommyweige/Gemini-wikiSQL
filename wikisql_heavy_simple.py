#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆWikiSQL Heavyé›†æˆ - é¿å…å¤æ‚çš„ä¾èµ–é—®é¢˜
ç›´æ¥ä½¿ç”¨OpenAI APIè¿›è¡Œå¤šæ™ºèƒ½ä½“åˆ†æ
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path
import yaml

from wikisql_llm_direct import WikiSQLDirectLLM

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class QuestionGenerationAgent:
    """é—®é¢˜ç”Ÿæˆæ™ºèƒ½ä½“ - å°†ç”¨æˆ·è¾“å…¥æ‹†è§£æˆ4ä¸ªä¸“é—¨çš„ç ”ç©¶é—®é¢˜"""
    
    def __init__(self, api_key: str, model: str = "gemini-2.5-flash"):
        self.api_key = api_key
        self.model = model
        
        # åˆå§‹åŒ–LLM
        try:
            from langchain_openai import ChatOpenAI
            base_url = "https://okjtgbhgemzb.eu-central-1.clawcloudrun.com"
            self.client = ChatOpenAI(
                model=self.model,
                temperature=0.1,
                base_url=f"{base_url}/v1",
                request_timeout=30,
                verbose=False
            )
            self.available = True
        except Exception as e:
            logger.warning(f"é—®é¢˜ç”Ÿæˆæ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.available = False
    
    def generate_specialized_questions(self, user_question: str, table_info: dict, generated_sql: str) -> List[str]:
        """ç”Ÿæˆ4ä¸ªä¸“é—¨çš„ç ”ç©¶é—®é¢˜ - åœç¹ç”¨æˆ¶æ ¸å¿ƒéœ€æ±‚"""
        if not self.available:
            return []
        
        prompt = f"""
You are a question generation expert. Create 4 natural language questions based on the original question, using a 1+3 structure: 1 original question + 3 transformed questions from different perspectives.

Original Question: {user_question}
Table Information: {json.dumps(table_info, ensure_ascii=False)}

Requirements:
1. First question: Keep the EXACT original question unchanged
2. Questions 2-4: Transform the original question from different angles while maintaining the same core intent
3. All questions must be natural language questions (NO SQL syntax allowed)
4. All questions must be in English
5. Focus on different aspects: specificity, context, verification

Example transformation patterns:
- Original: "What school did player number 21 play for?"
- Angle 1: "Which educational institution was attended by the athlete wearing jersey number 21?"
- Angle 2: "What is the academic background of the player identified as number 21?"
- Angle 3: "Can you identify the college or university associated with player 21?"

Please output in the following format:
ORIGINAL: {user_question}
SPECIFIC: [More specific version focusing on details and context]
ALTERNATIVE: [Alternative phrasing with different terminology]
VERIFICATION: [Verification-focused version asking for confirmation]
"""
        
        try:
            response = self.client.invoke(prompt)
            return self._parse_questions(response.content, user_question)
        except Exception as e:
            logger.error(f"ç”Ÿæˆä¸“é—¨é—®é¢˜å¤±è´¥: {e}")
            return []
    
    def _parse_questions(self, response: str, user_question: str) -> List[str]:
        """è§£æç”Ÿæˆçš„4ä¸ªé—®é¢˜"""
        questions = []
        lines = response.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('ORIGINAL:'):
                questions.append(line.replace('ORIGINAL:', '').strip())
            elif line.startswith('SPECIFIC:'):
                questions.append(line.replace('SPECIFIC:', '').strip())
            elif line.startswith('ALTERNATIVE:'):
                questions.append(line.replace('ALTERNATIVE:', '').strip())
            elif line.startswith('VERIFICATION:'):
                questions.append(line.replace('VERIFICATION:', '').strip())
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤çš„1+3ç»“æ„è‹±æ–‡é—®é¢˜
        if len(questions) != 4:
            questions = [
                user_question,  # ä¿æŒåŸå§‹é—®é¢˜
                f"Which specific details can help us better understand the question: '{user_question}'?",
                f"How can we rephrase the question '{user_question}' using different terminology?", 
                f"What evidence would confirm that we correctly answered '{user_question}'?"
            ]
        
        return questions

class SimpleHeavyAgent:
    """ç®€åŒ–ç‰ˆHeavyæ™ºèƒ½ä½“ - å›ç­”ä¸“é—¨çš„ç ”ç©¶é—®é¢˜"""
    
    def __init__(self, agent_id: int, api_key: str, model: str = "gemini-2.5-flash"):
        """
        åˆå§‹åŒ–ç®€åŒ–ç‰ˆæ™ºèƒ½ä½“
        
        Args:
            agent_id: æ™ºèƒ½ä½“ID
            api_key: APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹
        """
        self.agent_id = agent_id
        self.api_key = api_key
        self.model = model
        
        # å®šä¹‰æ™ºèƒ½ä½“è§’è‰²
        self.agent_types = {
            0: "Research Agent - æ•°æ®ç ”ç©¶ä¸“å®¶",
            1: "Analysis Agent - SQLåˆ†æä¸“å®¶", 
            2: "Alternatives Agent - æ›¿ä»£æ–¹æ¡ˆä¸“å®¶",
            3: "Verification Agent - éªŒè¯ä¸“å®¶"
        }
        
        self.role = self.agent_types.get(agent_id, "é€šç”¨åˆ†æå¸ˆ")
        
        # åˆå§‹åŒ–LangChain OpenAIå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨è‡ªå®šä¹‰base URLï¼‰
        try:
            from langchain_openai import ChatOpenAI
            
            base_url = "https://okjtgbhgemzb.eu-central-1.clawcloudrun.com"
            self.client = ChatOpenAI(
                model=self.model,
                temperature=0.1,
                base_url=f"{base_url}/v1",
                request_timeout=30,
                verbose=False
            )
            self.available = True
        except ImportError:
            logger.warning("langchain-openaiåº“æœªå®‰è£…ï¼ŒHeavyåŠŸèƒ½ä¸å¯ç”¨")
            self.available = False
        except Exception as e:
            logger.warning(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.available = False
    
    def answer_specialized_question(self, specialized_question: str, user_question: str, table_info: dict, generated_sql: str) -> dict:
        """
        å›ç­”ä¸“é—¨çš„ç ”ç©¶é—®é¢˜
        
        Args:
            specialized_question: ä¸“é—¨çš„ç ”ç©¶é—®é¢˜
            user_question: ç”¨æˆ·åŸå§‹é—®é¢˜
            table_info: è¡¨æ ¼ä¿¡æ¯
            generated_sql: ç”Ÿæˆçš„SQLæŸ¥è¯¢
            
        Returns:
            å›ç­”ç»“æœ
        """
        if not self.available:
            return {
                "agent_id": self.agent_id,
                "role": self.role,
                "error": "OpenAIå®¢æˆ·ç«¯ä¸å¯ç”¨",
                "analysis": None
            }
        
        # æ„å»ºä¸“é—¨é—®é¢˜çš„å›ç­”æç¤º
        answer_prompt = self._build_answer_prompt(
            specialized_question, user_question, table_info, generated_sql
        )
        
        try:
            # æ„å»ºå®Œæ•´æç¤º
            full_prompt = f"ç³»ç»Ÿ: ä½ æ˜¯ä¸€ä¸ª{self.role}ã€‚\n\nç”¨æˆ·: {answer_prompt}"
            
            response = self.client.invoke(full_prompt)
            answer_result = response.content
            
            return {
                "agent_id": self.agent_id,
                "role": self.role,
                "specialized_question": specialized_question,
                "answer": answer_result,
                "confidence": self._calculate_confidence(answer_result)
            }
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä½“ {self.agent_id} åˆ†æå¤±è´¥: {e}")
            return {
                "agent_id": self.agent_id,
                "role": self.role,
                "specialized_question": specialized_question,
                "error": str(e),
                "answer": None
            }
    
    def _build_answer_prompt(self, specialized_question: str, user_question: str, table_info: dict, sql: str) -> str:
        """Build specialized question answer prompt - Focus on user core needs with SQL execution"""
        return f"""
Your task is to help better answer the user's question: "{user_question}"

Specialized Research Question: {specialized_question}

Background Information:
- User Original Question: {user_question}
- Current Generated SQL: {sql}

Table Structure:
{json.dumps(table_info, indent=2, ensure_ascii=False)}

As {self.role}, please:

1. **Execute the SQL Query**: Analyze what the SQL query `{sql}` would return
2. **Explain the Query Logic**: Why this SQL approach was chosen for the user's question
3. **Check Multi-Condition Requirements**: Does the user question require multiple WHERE conditions?
4. **Interpret Results**: What the query results mean in context of the user's question
5. **Evaluate Correctness**: Does this SQL correctly answer "{user_question}"?
6. **Suggest Improvements**: If needed, propose better SQL queries or approaches

Please structure your response as:
- **SQL Analysis**: [What the query does step by step]
- **Query Reasoning**: [Why this approach was chosen]
- **Multi-Condition Check**: [Does the question require multiple conditions? Are they all present?]
- **Expected Results**: [What results this query would produce]
- **Correctness Assessment**: [Does it answer the user's question correctly?]
- **Recommendations**: [Any improvements, especially missing conditions or alternative approaches]

Special attention to multi-condition queries:
- Questions like "What player played guard for toronto in 1996-97?" need multiple conditions
- Check if all conditions from the user question are captured in the SQL
- Look for missing AND clauses that might be needed

IMPORTANT: Only suggest SQL improvements if there are CLEAR missing conditions or obvious errors.
- Don't suggest LIKE instead of = unless absolutely necessary
- Don't add LOWER(), UPPER(), or other functions unless required
- Keep suggestions simple and compatible with WikiSQL format
- Focus on missing WHERE conditions, not style improvements

Focus on helping answer "{user_question}" accurately and completely.
"""
    
    def _calculate_confidence(self, analysis: str) -> float:
        """Calculate analysis confidence based on English keywords"""
        if not analysis:
            return 0.0
        
        # English confidence keywords for SQL analysis
        confidence_keywords = [
            "correct", "accurate", "appropriate", "valid", "suitable",
            "recommend", "suggest", "should", "would", "effective",
            "optimal", "proper", "reliable", "consistent", "logical"
        ]
        
        # Convert to lowercase for case-insensitive matching
        analysis_lower = analysis.lower()
        keyword_count = sum(1 for keyword in confidence_keywords if keyword in analysis_lower)
        
        # Base confidence calculation
        base_confidence = min(keyword_count / 10, 0.8)  # Max 0.8 from keywords
        
        # Bonus for structured analysis (our format)
        structure_bonus = 0.0
        if "**SQL Analysis**" in analysis:
            structure_bonus += 0.1
        if "**Query Reasoning**" in analysis:
            structure_bonus += 0.1
        if "**Expected Results**" in analysis:
            structure_bonus += 0.05
        if "**Correctness Assessment**" in analysis:
            structure_bonus += 0.05
        
        return min(base_confidence + structure_bonus, 1.0)
    
    def _extract_recommendations(self, analysis: str) -> List[str]:
        """æå–å»ºè®®"""
        if not analysis:
            return []
        
        recommendations = []
        lines = analysis.split('\n')
        
        for line in lines:
            line = line.strip()
            if any(keyword in line for keyword in ["å»ºè®®", "æ¨è", "åº”è¯¥", "éœ€è¦", "å¯ä»¥"]):
                if len(line) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                    recommendations.append(line)
        
        return recommendations[:5]  # æœ€å¤šè¿”å›5ä¸ªå»ºè®®

class SimpleHeavyOrchestrator:
    """çœŸæ­£çš„Make It Heavyç¼–æ’å™¨ - æŒ‰ç…§æ­£ç¡®æµç¨‹å®ç°"""
    
    def __init__(self, api_key: str, model: str = "gemini-2.5-flash"):
        """
        åˆå§‹åŒ–Make It Heavyç¼–æ’å™¨
        
        Args:
            api_key: APIå¯†é’¥ï¼ˆä¸WikiSQLç›¸åŒï¼‰
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.api_key = api_key
        self.model = model
        
        # åˆå§‹åŒ–Question Generation Agent
        self.question_generator = SimpleHeavyAgent(-1, api_key, model)
        
        # åˆå§‹åŒ–4ä¸ªä¸“é—¨æ™ºèƒ½ä½“
        self.agents = []
        agent_roles = [
            "SQL Research Agent - Deep SQL query analysis and data exploration",
            "SQL Logic Agent - Query logic validation and reasoning analysis", 
            "SQL Alternatives Agent - Alternative query approaches and optimization",
            "SQL Verification Agent - Query result verification and accuracy assessment"
        ]
        
        for i, role in enumerate(agent_roles):
            agent = SimpleHeavyAgent(i, api_key, model)
            agent.role = role
            self.agents.append(agent)
        
        # åˆå§‹åŒ–Synthesis Agent
        self.synthesis_agent = SimpleHeavyAgent(99, api_key, model)
        self.synthesis_agent.role = "Synthesis Agent - ç»¼åˆåˆ†æå’Œæœ€ç»ˆç­”æ¡ˆç”Ÿæˆ"
        
        logger.info(f"åˆå§‹åŒ–äº†Make It Heavyç³»ç»Ÿ - Question Generator + 4ä¸ªä¸“é—¨æ™ºèƒ½ä½“ + Synthesis Agent (æ¨¡å‹: {model})")
    
    def heavy_sql_analysis(self, question: str, table_info: dict, generated_sql: str) -> dict:
        """
        æ‰§è¡ŒçœŸæ­£çš„Make It Heavyåˆ†ææµç¨‹
        
        æµç¨‹:
        1. Question Generation Agent - ç”Ÿæˆ4ä¸ªä¸“é—¨é—®é¢˜
        2. 4ä¸ªæ™ºèƒ½ä½“å¹¶è¡Œå›ç­”ä¸“é—¨é—®é¢˜
        3. Synthesis Agent - ç»¼åˆæ‰€æœ‰ç­”æ¡ˆ
        
        Args:
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            table_info: è¡¨æ ¼ä¿¡æ¯
            generated_sql: ç”Ÿæˆçš„SQLæŸ¥è¯¢
            
        Returns:
            ç»¼åˆåˆ†æç»“æœ
        """
        logger.info("å¼€å§‹Make It Heavyåˆ†ææµç¨‹...")
        
        # ç¬¬ä¸€æ­¥ï¼šQuestion Generation Agent - ç”Ÿæˆ4ä¸ªä¸“é—¨é—®é¢˜
        print("ğŸ§  ç¬¬ä¸€æ­¥ï¼šQuestion Generation Agent ç”Ÿæˆä¸“é—¨é—®é¢˜...")
        specialized_questions = self._generate_specialized_questions(question, table_info, generated_sql)
        
        if not specialized_questions:
            return {"error": "æ— æ³•ç”Ÿæˆä¸“é—¨é—®é¢˜"}
        
        print("âœ… ç”Ÿæˆäº†4ä¸ªä¸“é—¨é—®é¢˜:")
        for i, q in enumerate(specialized_questions, 1):
            print(f"  {i}. {q[:100]}...")
        
        # ç¬¬äºŒæ­¥ï¼š4ä¸ªæ™ºèƒ½ä½“å¹¶è¡Œæ‰§è¡Œ
        print("\nğŸš€ ç¬¬äºŒæ­¥ï¼š4ä¸ªæ™ºèƒ½ä½“å¹¶è¡Œåˆ†æ...")
        agent_results = self._parallel_agent_execution(specialized_questions, question, table_info, generated_sql)
        
        # ç¬¬ä¸‰æ­¥ï¼šSynthesis Agentç»¼åˆåˆ†æ
        print("\nğŸ¯ ç¬¬ä¸‰æ­¥ï¼šSynthesis Agent ç»¼åˆåˆ†æ...")
        final_synthesis = self._synthesis_analysis(question, agent_results, generated_sql)
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ”¹é€²SQL
        improved_sql = self._extract_improved_sql(final_synthesis, generated_sql)
        
        return {
            "question": question,
            "generated_sql": generated_sql,
            "improved_sql": improved_sql,  # Heavyåˆ†ææ”¹é€²çš„SQL
            "specialized_questions": specialized_questions,
            "agent_analyses": agent_results,
            "synthesis": final_synthesis,
            "overall_confidence": final_synthesis.get("confidence", 0.0),
            "final_answer": final_synthesis.get("final_answer", ""),
            "make_it_heavy_flow": True
        }
    
    def _generate_specialized_questions(self, question: str, table_info: dict, generated_sql: str) -> list:
        """
        ç¬¬ä¸€æ­¥ï¼šQuestion Generation Agent ç”Ÿæˆ4å€‹å°ˆé–€å•é¡Œ
        
        Args:
            question: è‡ªç„¶èªè¨€å•é¡Œ
            table_info: è¡¨æ ¼ä¿¡æ¯
            generated_sql: ç”Ÿæˆçš„SQLæŸ¥è©¢
            
        Returns:
            4å€‹å°ˆé–€å•é¡Œçš„åˆ—è¡¨
        """
        # ä½¿ç”¨Question Generation Agentç”Ÿæˆå°ˆé–€å•é¡Œ
        question_generator = QuestionGenerationAgent(self.api_key)
        specialized_questions = question_generator.generate_specialized_questions(
            question, table_info, generated_sql
        )
        
        if not specialized_questions:
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤çš„1+3ç»“æ„è‹±æ–‡é—®é¢˜
            specialized_questions = [
                question,  # ä¿æŒåŸå§‹é—®é¢˜
                f"Which specific details and conditions are most important when answering: '{question}'?",
                f"How can we rephrase this inquiry using different terminology: '{question}'?",
                f"What evidence would confirm we have correctly answered: '{question}'?"
            ]
        
        return specialized_questions
    
    def _parallel_agent_execution(self, specialized_questions: list, original_question: str, table_info: dict, generated_sql: str) -> list:
        """
        ç¬¬äºŒæ­¥ï¼š4å€‹å°ˆæ¥­æ™ºèƒ½é«”ä¸¦è¡ŒåŸ·è¡Œåˆ†æ
        
        Args:
            specialized_questions: 4å€‹å°ˆé–€å•é¡Œ
            original_question: åŸå§‹å•é¡Œ
            table_info: è¡¨æ ¼ä¿¡æ¯
            generated_sql: ç”Ÿæˆçš„SQL
            
        Returns:
            æ™ºèƒ½é«”åˆ†æçµæœåˆ—è¡¨
        """
        import concurrent.futures
        import time
        
        agent_results = []
        
        def execute_agent_analysis(agent, specialized_question, agent_id):
            """å–®å€‹æ™ºèƒ½é«”åŸ·è¡Œåˆ†æ"""
            try:
                if not agent.available:
                    return {
                        "agent_id": agent_id,
                        "role": agent.role,
                        "specialized_question": specialized_question,
                        "error": "æ™ºèƒ½é«”ä¸å¯ç”¨",
                        "answer": None,
                        "confidence": 0.0
                    }
                
                # åŸ·è¡Œå°ˆé–€å•é¡Œåˆ†æ
                result = agent.answer_specialized_question(
                    specialized_question, original_question, table_info, generated_sql
                )
                return result
                
            except Exception as e:
                return {
                    "agent_id": agent_id,
                    "role": agent.role,
                    "specialized_question": specialized_question,
                    "error": str(e),
                    "answer": None,
                    "confidence": 0.0
                }
        
        # ä¸¦è¡ŒåŸ·è¡Œ4å€‹æ™ºèƒ½é«”
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            # æäº¤ä»»å‹™
            future_to_agent = {}
            for i, (agent, spec_question) in enumerate(zip(self.agents, specialized_questions)):
                future = executor.submit(execute_agent_analysis, agent, spec_question, i)
                future_to_agent[future] = (agent, i)
            
            # æ”¶é›†çµæœ
            for future in concurrent.futures.as_completed(future_to_agent, timeout=120):
                try:
                    result = future.result()
                    agent_results.append(result)
                except Exception as e:
                    agent, agent_id = future_to_agent[future]
                    agent_results.append({
                        "agent_id": agent_id,
                        "role": agent.role,
                        "error": f"åŸ·è¡Œè¶…æ™‚æˆ–å¤±æ•—: {str(e)}",
                        "answer": None,
                        "confidence": 0.0
                    })
        
        # æŒ‰agent_idæ’åº
        agent_results.sort(key=lambda x: x.get("agent_id", 0))
        return agent_results
    
    def _synthesis_analysis(self, original_question: str, agent_results: list, generated_sql: str) -> dict:
        """
        ç¬¬ä¸‰æ­¥ï¼šSynthesis Agent ç¶œåˆæ‰€æœ‰æ™ºèƒ½é«”çš„åˆ†æçµæœ
        
        Args:
            original_question: åŸå§‹å•é¡Œ
            agent_results: æ™ºèƒ½é«”åˆ†æçµæœ
            generated_sql: ç”Ÿæˆçš„SQL
            
        Returns:
            ç¶œåˆåˆ†æçµæœ
        """
        # æ”¶é›†æ‰€æœ‰æˆåŠŸçš„åˆ†æ
        successful_results = [r for r in agent_results if not r.get("error")]
        
        if not successful_results:
            return {
                "error": "æ²¡æœ‰æˆåŠŸçš„æ™ºèƒ½ä½“åˆ†æ", 
                "confidence": 0.0,
                "successful_agents": 0,
                "total_agents": len(agent_results),
                "valid_analyses": 0,
                "final_answer": "æ‰€æœ‰æ™ºèƒ½ä½“åˆ†æéƒ½å¤±è´¥äº†"
            }
        
        # Build synthesis analysis prompt - Focus on user core question
        synthesis_prompt = f"""
As Synthesis Agent, your task is to synthesize the analysis from 4 professional agents, with the ultimate goal of ensuring we correctly answer the user's question.

User Question: {original_question}
Current SQL Solution: {generated_sql}

Analysis Results from 4 Professional Agents:
"""
        
        for result in successful_results:
            role = result.get("role", "Unknown Role")
            question = result.get("specialized_question", "")
            answer = result.get("answer", "")
            synthesis_prompt += f"""
{role}:
Specialized Question: {question}
Analysis Answer: {answer}

---
"""
        
        synthesis_prompt += f"""
As Synthesis Agent, analyze the SQL query results and recommendations from all 4 agents to provide a comprehensive answer to: "{original_question}"

Please synthesize their findings by:

1. **SQL Query Evaluation**: Compare how each agent analyzed the SQL query `{generated_sql}`
2. **Results Analysis**: Synthesize what each agent found about the query results and their correctness
3. **Consensus Assessment**: Where do the agents agree/disagree about the SQL approach?
4. **Improved SQL**: If agents suggest improvements, provide the corrected SQL query
5. **Final Answer**: Based on all agent analyses, what is the best answer to "{original_question}"?
6. **Confidence Score**: Overall confidence in the final answer (0-1)

Structure your response as:
- **Query Assessment**: [Combined evaluation of the SQL query]
- **Agent Consensus**: [Where agents agree and disagree]
- **Improved SQL**: [If needed, provide corrected SQL query in format: ```sql\nSELECT ... \n```]
- **Final Answer**: [Definitive answer to the user's question]
- **Confidence**: [Number between 0-1]

IMPORTANT: If the agents identified missing conditions or SQL errors, provide the corrected SQL query in a code block like this:
```sql
SELECT col0 FROM table_name WHERE col1='condition1' AND col2='condition2';
```

CRITICAL GUIDELINES for SQL improvements:
1. Keep SQL simple and compatible with WikiSQL format
2. Use exact matches (=) instead of LIKE unless absolutely necessary
3. Don't add unnecessary functions like LOWER(), UPPER(), etc.
4. Stick to basic SELECT, FROM, WHERE, AND structure
5. Only suggest improvements if there are clear missing conditions or obvious errors

Focus on providing the most accurate answer to "{original_question}" based on all agent insights.
"""
        
        try:
            response = self.synthesis_agent.client.invoke(synthesis_prompt)
            synthesis_content = response.content
            
            # ä»synthesiså†…å®¹ä¸­æå–ç½®ä¿¡åº¦
            confidence = self._extract_confidence_from_synthesis(synthesis_content, successful_results)
            
            return {
                "synthesis_content": synthesis_content,
                "confidence": confidence,
                "successful_agents": len(successful_results),
                "total_agents": len(agent_results),
                "final_answer": synthesis_content,
                "valid_analyses": len(successful_results)
            }
            
        except Exception as e:
            logger.error(f"Synthesis Agentåˆ†æå¤±è´¥: {e}")
            return {
                "error": f"ç»¼åˆåˆ†æå¤±è´¥: {e}",
                "confidence": 0.0,
                "successful_agents": len(successful_results),
                "total_agents": len(agent_results),
                "valid_analyses": len(successful_results),
                "final_answer": f"Synthesis Agentå¤±è´¥ï¼Œä½†{len(successful_results)}ä¸ªæ™ºèƒ½ä½“æˆåŠŸå®Œæˆåˆ†æ"
            }
    
    def _extract_confidence_from_synthesis(self, synthesis_content: str, successful_results: list) -> float:
        """ä»synthesiså†…å®¹å’Œæ™ºèƒ½ä½“ç»“æœä¸­æå–çœŸå®çš„ç½®ä¿¡åº¦"""
        import re
        
        # 1. å°è¯•ä»synthesiså†…å®¹ä¸­æå–æ˜ç¡®çš„ç½®ä¿¡åº¦
        confidence_patterns = [
            r'\*\*Confidence\*\*[ï¼š:]\s*([0-9.]+)',
            r'ç½®ä¿¡åº¦[ï¼š:]\s*([0-9.]+)',
            r'confidence[ï¼š:]\s*([0-9.]+)',
            r'Confidence Score[ï¼š:]\s*([0-9.]+)',
            r'Overall confidence[ï¼š:]\s*([0-9.]+)',
            r'([0-9.]+)\s*(?:out of|/)\s*1',
            r'([0-9.]+)\s*(?:%|percent)',
        ]
        
        for pattern in confidence_patterns:
            matches = re.findall(pattern, synthesis_content, re.IGNORECASE)
            if matches:
                try:
                    conf_value = float(matches[0])
                    # å¦‚æœæ˜¯ç™¾åˆ†æ¯”ï¼Œè½¬æ¢ä¸º0-1èŒƒå›´
                    if conf_value > 1:
                        conf_value = conf_value / 100
                    if 0 <= conf_value <= 1:
                        return conf_value
                except ValueError:
                    continue
        
        # 2. åŸºäºæ™ºèƒ½ä½“ç»“æœè®¡ç®—ç½®ä¿¡åº¦
        if successful_results:
            agent_confidences = [r.get("confidence", 0.0) for r in successful_results]
            avg_agent_confidence = sum(agent_confidences) / len(agent_confidences)
            
            # 3. åŸºäºsynthesiså†…å®¹è´¨é‡è°ƒæ•´ç½®ä¿¡åº¦
            quality_indicators = [
                "correct", "accurate", "appropriate", "valid", "suitable",
                "recommend", "improved", "better", "optimal", "effective"
            ]
            
            negative_indicators = [
                "error", "incorrect", "wrong", "missing", "failed",
                "unclear", "ambiguous", "problematic", "insufficient"
            ]
            
            content_lower = synthesis_content.lower()
            positive_count = sum(1 for indicator in quality_indicators if indicator in content_lower)
            negative_count = sum(1 for indicator in negative_indicators if indicator in content_lower)
            
            # è´¨é‡è°ƒæ•´å› å­
            quality_factor = (positive_count - negative_count * 0.5) / 10
            quality_factor = max(-0.3, min(0.3, quality_factor))  # é™åˆ¶åœ¨-0.3åˆ°0.3ä¹‹é—´
            
            # æˆåŠŸæ™ºèƒ½ä½“æ¯”ä¾‹è°ƒæ•´
            success_ratio = len(successful_results) / 4  # æ€»å…±4ä¸ªæ™ºèƒ½ä½“
            
            # ç»¼åˆè®¡ç®—ç½®ä¿¡åº¦
            final_confidence = avg_agent_confidence * success_ratio + quality_factor
            final_confidence = max(0.0, min(1.0, final_confidence))  # ç¡®ä¿åœ¨0-1èŒƒå›´å†…
            
            return final_confidence
        
        # 4. é»˜è®¤ç½®ä¿¡åº¦ï¼ˆå¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼‰
        return 0.5
    
    def _extract_improved_sql(self, synthesis_result: dict, original_sql: str) -> str:
        """å¾Synthesisçµæœä¸­æå–æ”¹é€²çš„SQLæŸ¥è©¢"""
        if synthesis_result.get("error"):
            return original_sql
        
        final_answer = synthesis_result.get("final_answer", "")
        
        # å°‹æ‰¾SQLæŸ¥è©¢å»ºè­°
        import re
        
        # æ›´å…¨é¢çš„SQLä»£ç¢¼å¡Šæ¨¡å¼
        sql_patterns = [
            # æ¨™æº–ä»£ç¢¼å¡Š
            r'```sql\s*\n(.*?)\n```',
            r'```\s*\n(SELECT.*?;)\s*\n```',
            # Improved SQL éƒ¨åˆ†
            r'\*\*Improved SQL\*\*.*?```sql\s*\n(.*?)\n```',
            r'\*\*Improved SQL\*\*.*?[:ï¼š]\s*(SELECT.*?;)',
            # ä¸€èˆ¬SQLå»ºè­°
            r'å»ºè­°.*?SQL.*?[:ï¼š]\s*(SELECT.*?;)',
            r'æ”¹é€².*?SQL.*?[:ï¼š]\s*(SELECT.*?;)',
            r'æ­£ç¢º.*?SQL.*?[:ï¼š]\s*(SELECT.*?;)',
            r'corrected.*?SQL.*?[:ï¼š]\s*(SELECT.*?;)',
            r'improved.*?SQL.*?[:ï¼š]\s*(SELECT.*?;)',
            # ç›´æ¥çš„SELECTèªå¥
            r'(SELECT\s+col\d+.*?WHERE.*?;)',
            r'(SELECT\s+.*?FROM\s+.*?WHERE.*?AND.*?;)',
        ]
        
        for pattern in sql_patterns:
            matches = re.findall(pattern, final_answer, re.DOTALL | re.IGNORECASE)
            if matches:
                improved_sql = matches[0].strip()
                # æ¸…ç†SQL
                improved_sql = improved_sql.replace('\n', ' ').replace('\r', ' ')
                improved_sql = ' '.join(improved_sql.split())  # è¦ç¯„åŒ–ç©ºæ ¼
                
                # ç¢ºä¿SQLä»¥åˆ†è™Ÿçµå°¾
                if not improved_sql.endswith(';'):
                    improved_sql += ';'
                
                # æª¢æŸ¥æ˜¯å¦çœŸçš„æ˜¯æ”¹é€²çš„SQL - æ›´åš´æ ¼çš„é©—è­‰
                if (improved_sql and 
                    improved_sql != original_sql and 
                    'SELECT' in improved_sql.upper() and
                    len(improved_sql) > 10 and
                    self._is_valid_improvement(improved_sql, original_sql)):
                    logger.info(f"Heavyåˆ†ææå–åˆ°æ”¹é€²SQL: {improved_sql}")
                    return improved_sql
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ”¹é€²çš„SQLï¼Œè¿”å›åŸå§‹SQL
        logger.info(f"æœªæ‰¾åˆ°æ”¹é€²SQLï¼Œä½¿ç”¨åŸå§‹SQL: {original_sql}")
        return original_sql
    
    def _is_valid_improvement(self, improved_sql: str, original_sql: str) -> bool:
        """é©—è­‰æ”¹é€²çš„SQLæ˜¯å¦çœŸçš„æ¯”åŸå§‹SQLæ›´å¥½"""
        import re
        
        # æå–WHEREæ¢ä»¶æ•¸é‡
        def count_conditions(sql):
            where_match = re.search(r'WHERE\s+(.+?)(?:\s+ORDER|\s+GROUP|\s+LIMIT|;|$)', sql, re.IGNORECASE)
            if not where_match:
                return 0
            where_clause = where_match.group(1)
            return len(re.findall(r'\bAND\b', where_clause, re.IGNORECASE)) + 1
        
        original_conditions = count_conditions(original_sql)
        improved_conditions = count_conditions(improved_sql)
        
        # æª¢æŸ¥æ˜¯å¦æ·»åŠ äº†æœ‰æ„ç¾©çš„æ¢ä»¶
        if improved_conditions > original_conditions:
            logger.info(f"SQLæ”¹é€²ï¼šæ·»åŠ äº† {improved_conditions - original_conditions} å€‹æ¢ä»¶")
            return True
        
        # æª¢æŸ¥æ˜¯å¦ä¿®å¾©äº†æ˜é¡¯çš„éŒ¯èª¤ï¼ˆå¦‚éŒ¯èª¤çš„åˆ—é¸æ“‡ï¼‰
        original_select = re.search(r'SELECT\s+(.*?)\s+FROM', original_sql, re.IGNORECASE)
        improved_select = re.search(r'SELECT\s+(.*?)\s+FROM', improved_sql, re.IGNORECASE)
        
        if original_select and improved_select:
            orig_cols = original_select.group(1).strip()
            impr_cols = improved_select.group(1).strip()
            
            # å¦‚æœåªæ˜¯æ”¹è®Šäº†é¸æ“‡çš„åˆ—ï¼Œéœ€è¦è¬¹æ…
            if orig_cols != impr_cols:
                logger.warning(f"SQLæ”¹é€²æ”¹è®Šäº†é¸æ“‡åˆ—ï¼š{orig_cols} -> {impr_cols}")
                # åªæœ‰åœ¨åŸå§‹SQLæ˜é¡¯éŒ¯èª¤æ™‚æ‰æ¥å—åˆ—çš„æ”¹è®Š
                return False
        
        # æª¢æŸ¥æ˜¯å¦æ·»åŠ äº†ä¸å¿…è¦çš„è¤‡é›œæ€§
        complexity_indicators = ['LIKE', 'LOWER', 'UPPER', 'CROSS APPLY', 'STRING_SPLIT', '%']
        improved_complexity = sum(1 for indicator in complexity_indicators if indicator in improved_sql.upper())
        original_complexity = sum(1 for indicator in complexity_indicators if indicator in original_sql.upper())
        
        if improved_complexity > original_complexity:
            logger.warning(f"SQLæ”¹é€²å¢åŠ äº†è¤‡é›œæ€§ï¼Œå¯èƒ½ä¸é©åˆWikiSQLæ ¼å¼")
            return False
        
        # å¦‚æœæ²’æœ‰æ˜é¡¯æ”¹é€²ï¼Œä¿æŒåŸå§‹SQL
        logger.info("SQLæ”¹é€²æ²’æœ‰æ˜é¡¯å„ªå‹¢ï¼Œä¿æŒåŸå§‹SQL")
        return False
    
    def _synthesize_results_old(self, agent_results: List[dict]) -> dict:
        """ç»¼åˆå¤šä¸ªæ™ºèƒ½ä½“çš„åˆ†æç»“æœ"""
        # æ”¶é›†æ‰€æœ‰å»ºè®®
        all_recommendations = []
        total_confidence = 0.0
        valid_analyses = 0
        
        for result in agent_results:
            if result.get("analysis") and not result.get("error"):
                all_recommendations.extend(result.get("recommendations", []))
                total_confidence += result.get("confidence", 0.0)
                valid_analyses += 1
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        avg_confidence = total_confidence / valid_analyses if valid_analyses > 0 else 0.0
        
        # å»é‡å’Œæ’åºå»ºè®®
        unique_recommendations = list(set(all_recommendations))
        
        # ç”Ÿæˆç»¼åˆè¯„ä¼°
        synthesis_summary = self._generate_synthesis_summary(agent_results)
        
        return {
            "confidence": avg_confidence,
            "recommendations": unique_recommendations[:10],  # æœ€å¤š10ä¸ªå»ºè®®
            "summary": synthesis_summary,
            "valid_analyses": valid_analyses,
            "total_agents": len(agent_results)
        }
    
    def _generate_synthesis_summary(self, agent_results: List[dict]) -> str:
        """ç”Ÿæˆç»¼åˆè¯„ä¼°æ‘˜è¦"""
        successful_analyses = [r for r in agent_results if not r.get("error")]
        failed_analyses = [r for r in agent_results if r.get("error")]
        
        summary_parts = []
        
        if successful_analyses:
            summary_parts.append(f"âœ… {len(successful_analyses)} ä¸ªæ™ºèƒ½ä½“æˆåŠŸå®Œæˆåˆ†æ")
            
            # æŒ‰è§’è‰²æ€»ç»“
            for result in successful_analyses:
                role = result.get("role", "æœªçŸ¥è§’è‰²")
                confidence = result.get("confidence", 0.0)
                summary_parts.append(f"  - {role}: ç½®ä¿¡åº¦ {confidence:.2f}")
        
        if failed_analyses:
            summary_parts.append(f"âŒ {len(failed_analyses)} ä¸ªæ™ºèƒ½ä½“åˆ†æå¤±è´¥")
        
        return "\n".join(summary_parts)

class WikiSQLDirectLLMSimpleHeavy(WikiSQLDirectLLM):
    """ç®€åŒ–ç‰ˆHeavyå¢å¼ºWikiSQLåŠ©æ‰‹"""
    
    def __init__(self, api_key: str, enable_heavy: bool = True, **kwargs):
        """åˆå§‹åŒ–ç®€åŒ–ç‰ˆHeavyåŠ©æ‰‹"""
        super().__init__(api_key, **kwargs)
        
        # åˆå§‹åŒ–ç®€åŒ–ç‰ˆHeavyç¼–æ’å™¨ï¼ˆä½¿ç”¨ç›¸åŒçš„APIå¯†é’¥å’Œæ¨¡å‹ï¼‰
        if enable_heavy:
            try:
                # è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
                current_model = getattr(self.llm, 'model_name', 'gemini-2.5-flash')
                self.heavy_orchestrator = SimpleHeavyOrchestrator(api_key, current_model)
                self.heavy_enabled = True
                logger.info(f"âœ… ç®€åŒ–ç‰ˆHeavyæ¨¡å¼å·²å¯ç”¨ï¼ˆæ¨¡å‹: {current_model}ï¼‰")
            except Exception as e:
                logger.warning(f"âš ï¸ ç®€åŒ–ç‰ˆHeavyæ¨¡å¼åˆå§‹åŒ–å¤±è´¥: {e}")
                self.heavy_orchestrator = None
                self.heavy_enabled = False
        else:
            logger.info("Heavyæ¨¡å¼å·²ç¦ç”¨")
            self.heavy_orchestrator = None
            self.heavy_enabled = False
    
    def generate_sql_with_heavy_analysis(self, question: str, table_id: str) -> dict:
        """
        ç”ŸæˆSQLå¹¶è¿›è¡ŒHeavyåˆ†æ
        
        Args:
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            table_id: è¡¨æ ¼ID
            
        Returns:
            åŒ…å«Heavyåˆ†æçš„ç»“æœ
        """
        # 1. ç”ŸæˆåŸºç¡€SQL
        basic_sql = self.generate_sql(question, table_id)
        
        result = {
            "question": question,
            "table_id": table_id,
            "basic_sql": basic_sql,
            "heavy_analysis": None,
            "heavy_enabled": self.heavy_enabled
        }
        
        # 2. å¦‚æœHeavyæ¨¡å¼å¯ç”¨ï¼Œè¿›è¡Œæ·±åº¦åˆ†æ
        if self.heavy_enabled and basic_sql:
            try:
                table_info = self._get_table_info_for_heavy(table_id)
                heavy_analysis = self.heavy_orchestrator.heavy_sql_analysis(
                    question, table_info, basic_sql
                )
                result["heavy_analysis"] = heavy_analysis
                
                logger.info(f"âœ… ç®€åŒ–ç‰ˆHeavyåˆ†æå®Œæˆï¼Œç½®ä¿¡åº¦: {heavy_analysis.get('overall_confidence', 0.0):.2f}")
                
            except Exception as e:
                logger.error(f"âŒ ç®€åŒ–ç‰ˆHeavyåˆ†æå¤±è´¥: {e}")
                result["heavy_error"] = str(e)
        
        return result
    
    def _get_table_info_for_heavy(self, table_id: str) -> dict:
        """è·å–è¡¨æ ¼ä¿¡æ¯ç”¨äºHeavyåˆ†æ"""
        if table_id not in self.current_tables:
            return {}
        
        table = self.current_tables[table_id]
        
        return {
            "table_id": table_id,
            "headers": table.header,
            "types": table.types,
            "sample_rows": table.rows[:3] if table.rows else [],
            "total_rows": len(table.rows),
            "db_table_name": self.current_table_mapping.get(table_id, "unknown")
        }
    
    def query_with_heavy(self, question: str, table_id: Optional[str] = None) -> dict:
        """
        æ‰§è¡Œå¸¦Heavyåˆ†æçš„æŸ¥è¯¢
        
        Args:
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            table_id: è¡¨æ ¼ID
            
        Returns:
            æŸ¥è¯¢ç»“æœå’ŒHeavyåˆ†æ
        """
        # æ¨æ–­table_idï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not table_id and self.current_questions:
            for q in self.current_questions:
                if question.lower() in q.question.lower():
                    table_id = q.table_id
                    break
            if not table_id:
                table_id = self.current_questions[0].table_id
        
        if not table_id:
            return {"error": "æ— æ³•ç¡®å®šè¡¨æ ¼ID"}
        
        # ç”ŸæˆSQLå’ŒHeavyåˆ†æ
        heavy_result = self.generate_sql_with_heavy_analysis(question, table_id)
        
        # æ‰§è¡ŒSQLè·å–ç»“æœ
        if heavy_result.get("basic_sql"):
            try:
                query_result = self.execute_sql(heavy_result["basic_sql"])
                heavy_result["query_result"] = query_result
            except Exception as e:
                heavy_result["query_error"] = str(e)
        
        return heavy_result

def main():
    """æµ‹è¯•ç®€åŒ–ç‰ˆWikiSQL Heavyé›†æˆ"""
    print("ğŸš€ WikiSQL ç®€åŒ–ç‰ˆHeavy Integration æµ‹è¯•")
    print("=" * 60)
    
    # è·å–APIå¯†é’¥
    wikisql_api_key = input("è¯·è¾“å…¥ä½ çš„WikiSQL APIå¯†é’¥: ").strip()
    if not wikisql_api_key:
        print("âŒ éœ€è¦æä¾›WikiSQL APIå¯†é’¥")
        return
    
    openai_api_key = input("è¯·è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥ (ç”¨äºHeavyåˆ†æï¼Œå¯é€‰): ").strip()
    
    try:
        # åˆå§‹åŒ–ç®€åŒ–ç‰ˆHeavyåŠ©æ‰‹
        print("åˆå§‹åŒ–ç®€åŒ–ç‰ˆWikiSQL HeavyåŠ©æ‰‹...")
        assistant = WikiSQLDirectLLMSimpleHeavy(
            wikisql_api_key, 
            openai_api_key=openai_api_key
        )
        
        if assistant.heavy_enabled:
            print("âœ… ç®€åŒ–ç‰ˆHeavyæ¨¡å¼å·²å¯ç”¨")
        else:
            print("âš ï¸ Heavyæ¨¡å¼æœªå¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨¡å¼")
        
        # åŠ è½½æ•°æ®é›†
        print("åŠ è½½WikiSQLæ•°æ®é›†...")
        assistant.load_wikisql_dataset("dev", limit=2)
        
        # æµ‹è¯•æŸ¥è¯¢
        if assistant.current_questions:
            test_question = assistant.current_questions[0].question
            print(f"\næµ‹è¯•é—®é¢˜: {test_question}")
            
            if assistant.heavy_enabled:
                # æ‰§è¡ŒHeavyæŸ¥è¯¢
                print("æ‰§è¡Œç®€åŒ–ç‰ˆHeavyåˆ†æ...")
                heavy_result = assistant.query_with_heavy(test_question)
                
                # æ˜¾ç¤ºç»“æœ
                print("\n" + "=" * 60)
                print("ç®€åŒ–ç‰ˆHeavyåˆ†æç»“æœ:")
                print("=" * 60)
                
                if heavy_result.get("heavy_analysis"):
                    analysis = heavy_result["heavy_analysis"]
                    print(f"ç½®ä¿¡åº¦: {analysis.get('overall_confidence', 0.0):.2f}")
                    print(f"æœ‰æ•ˆåˆ†æ: {analysis['synthesis']['valid_analyses']}/{analysis['synthesis']['total_agents']}")
                    
                    recommendations = analysis.get('final_recommendations', [])
                    if recommendations:
                        print(f"\nä¸»è¦å»ºè®® (å‰3ä¸ª):")
                        for i, rec in enumerate(recommendations[:3], 1):
                            print(f"  {i}. {rec}")
                
                if heavy_result.get("query_result"):
                    print(f"\næŸ¥è¯¢ç»“æœ: {heavy_result['query_result']}")
            else:
                # åŸºç¡€æŸ¥è¯¢
                result = assistant.query(test_question)
                print(f"åŸºç¡€æŸ¥è¯¢ç»“æœ: {result}")
        
        print("\nâœ… ç®€åŒ–ç‰ˆHeavyé›†æˆæµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()